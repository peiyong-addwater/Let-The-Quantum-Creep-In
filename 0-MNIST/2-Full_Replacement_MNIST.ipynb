{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-02T16:10:37.033986Z",
     "iopub.status.busy": "2024-04-02T16:10:37.033383Z",
     "iopub.status.idle": "2024-04-02T16:10:43.549089Z",
     "shell.execute_reply": "2024-04-02T16:10:43.548169Z",
     "shell.execute_reply.started": "2024-04-02T16:10:37.033958Z"
    },
    "id": "5ebnFsErY0EM",
    "outputId": "e8932b66-715c-467f-912a-8b449c518214",
    "scrolled": true,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-07T14:04:36.882723Z",
     "start_time": "2024-04-07T14:02:47.064346Z"
    }
   },
   "source": [
    "# Install packages\n",
    "!pip install torch torchvision torchaudio --upgrade\n",
    "!pip install pennylane cotengra quimb torchmetrics --upgrade\n",
    "#!pip install -U \"jax[cuda12_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (1.12.1+cu116)\r\n",
      "Collecting torch\r\n",
      "  Downloading torch-2.2.2-cp39-cp39-manylinux1_x86_64.whl (755.5 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m755.5/755.5 MB\u001B[0m \u001B[31m2.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.13.1+cu116)\r\n",
      "Collecting torchvision\r\n",
      "  Downloading torchvision-0.17.2-cp39-cp39-manylinux1_x86_64.whl (6.9 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.9/6.9 MB\u001B[0m \u001B[31m62.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: torchaudio in /usr/local/lib/python3.9/dist-packages (0.12.1+cu116)\r\n",
      "Collecting torchaudio\r\n",
      "  Downloading torchaudio-2.2.2-cp39-cp39-manylinux1_x86_64.whl (3.3 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.3/3.3 MB\u001B[0m \u001B[31m102.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.0)\r\n",
      "Collecting nvidia-curand-cu12==10.3.2.106\r\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m56.5/56.5 MB\u001B[0m \u001B[31m35.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cusolver-cu12==11.4.5.107\r\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m124.2/124.2 MB\u001B[0m \u001B[31m15.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m14.1/14.1 MB\u001B[0m \u001B[31m93.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cudnn-cu12==8.9.2.26\r\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m731.7/731.7 MB\u001B[0m \u001B[31m3.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from torch) (2023.1.0)\r\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106\r\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m196.0/196.0 MB\u001B[0m \u001B[31m11.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting triton==2.2.0\r\n",
      "  Downloading triton-2.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m167.9/167.9 MB\u001B[0m \u001B[31m14.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-nvtx-cu12==12.1.105\r\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m99.1/99.1 kB\u001B[0m \u001B[31m34.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m823.6/823.6 kB\u001B[0m \u001B[31m38.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cublas-cu12==12.1.3.1\r\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m410.6/410.6 MB\u001B[0m \u001B[31m6.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.9.0)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m23.7/23.7 MB\u001B[0m \u001B[31m67.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting sympy\r\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.7/5.7 MB\u001B[0m \u001B[31m98.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0mta \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-nccl-cu12==2.19.3\r\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m166.0/166.0 MB\u001B[0m \u001B[31m14.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cufft-cu12==11.0.2.54\r\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m121.6/121.6 MB\u001B[0m \u001B[31m18.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\r\n",
      "Collecting typing-extensions>=4.8.0\r\n",
      "  Downloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\r\n",
      "Collecting nvidia-nvjitlink-cu12\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m21.1/21.1 MB\u001B[0m \u001B[31m74.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.23.4)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (9.2.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\r\n",
      "Collecting mpmath>=0.19\r\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m536.2/536.2 kB\u001B[0m \u001B[31m86.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: mpmath, typing-extensions, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\r\n",
      "  Attempting uninstall: typing-extensions\r\n",
      "    Found existing installation: typing_extensions 4.4.0\r\n",
      "    Uninstalling typing_extensions-4.4.0:\r\n",
      "      Successfully uninstalled typing_extensions-4.4.0\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 1.12.1+cu116\r\n",
      "    Uninstalling torch-1.12.1+cu116:\r\n",
      "      Successfully uninstalled torch-1.12.1+cu116\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.13.1+cu116\r\n",
      "    Uninstalling torchvision-0.13.1+cu116:\r\n",
      "      Successfully uninstalled torchvision-0.13.1+cu116\r\n",
      "  Attempting uninstall: torchaudio\r\n",
      "    Found existing installation: torchaudio 0.12.1+cu116\r\n",
      "    Uninstalling torchaudio-0.12.1+cu116:\r\n",
      "      Successfully uninstalled torchaudio-0.12.1+cu116\r\n",
      "Successfully installed mpmath-1.3.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 sympy-1.12 torch-2.2.2 torchaudio-2.2.2 torchvision-0.17.2 triton-2.2.0 typing-extensions-4.11.0\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0mCollecting pennylane\r\n",
      "  Downloading PennyLane-0.35.1-py3-none-any.whl (1.6 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.6/1.6 MB\u001B[0m \u001B[31m62.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting cotengra\r\n",
      "  Downloading cotengra-0.5.6-py3-none-any.whl (148 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m148.0/148.0 kB\u001B[0m \u001B[31m48.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting quimb\r\n",
      "  Downloading quimb-1.7.3-py3-none-any.whl (500 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m500.7/500.7 kB\u001B[0m \u001B[31m80.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting torchmetrics\r\n",
      "  Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m841.5/841.5 kB\u001B[0m \u001B[31m39.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting toml\r\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\r\n",
      "Collecting appdirs\r\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\r\n",
      "Collecting semantic-version>=2.7\r\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from pennylane) (2.28.2)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from pennylane) (3.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from pennylane) (1.23.4)\r\n",
      "Collecting autoray>=0.6.1\r\n",
      "  Downloading autoray-0.6.9-py3-none-any.whl (49 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m49.8/49.8 kB\u001B[0m \u001B[31m20.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting pennylane-lightning>=0.35\r\n",
      "  Downloading PennyLane_Lightning-0.35.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.5 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m18.5/18.5 MB\u001B[0m \u001B[31m53.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting rustworkx\r\n",
      "  Downloading rustworkx-0.14.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.1/2.1 MB\u001B[0m \u001B[31m71.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from pennylane) (1.9.2)\r\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from pennylane) (4.11.0)\r\n",
      "Collecting autograd\r\n",
      "  Downloading autograd-1.6.2-py3-none-any.whl (49 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m49.3/49.3 kB\u001B[0m \u001B[31m19.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: cachetools in /usr/local/lib/python3.9/dist-packages (from pennylane) (5.3.0)\r\n",
      "Requirement already satisfied: tqdm>=4 in /usr/local/lib/python3.9/dist-packages (from quimb) (4.64.1)\r\n",
      "Collecting numba>=0.39\r\n",
      "  Downloading numba-0.59.1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.7/3.7 MB\u001B[0m \u001B[31m43.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0mm\r\n",
      "\u001B[?25hCollecting cytoolz>=0.8.0\r\n",
      "  Downloading cytoolz-0.12.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m108.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: psutil>=4.3.1 in /usr/local/lib/python3.9/dist-packages (from quimb) (5.9.4)\r\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (2.2.2)\r\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (23.0)\r\n",
      "Collecting lightning-utilities>=0.8.0\r\n",
      "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\r\n",
      "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from cytoolz>=0.8.0->quimb) (0.12.0)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (66.1.1)\r\n",
      "Collecting llvmlite<0.43,>=0.42.0dev0\r\n",
      "  Downloading llvmlite-0.42.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m43.8/43.8 MB\u001B[0m \u001B[31m34.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.3.1)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.0.106)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (10.3.2.106)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (2023.1.0)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (2.19.3)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (8.9.2.26)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\r\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (2.2.0)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.2)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (3.9.0)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (11.0.2.54)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (11.4.5.107)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.9/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics) (12.4.127)\r\n",
      "Requirement already satisfied: future>=0.15.2 in /usr/lib/python3/dist-packages (from autograd->pennylane) (0.18.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->pennylane) (2.1.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->pennylane) (2.8)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->pennylane) (1.26.14)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->pennylane) (2019.11.28)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.2)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\r\n",
      "Installing collected packages: appdirs, toml, semantic-version, rustworkx, llvmlite, lightning-utilities, cytoolz, autoray, autograd, numba, cotengra, quimb, torchmetrics, pennylane-lightning, pennylane\r\n",
      "Successfully installed appdirs-1.4.4 autograd-1.6.2 autoray-0.6.9 cotengra-0.5.6 cytoolz-0.12.3 lightning-utilities-0.11.2 llvmlite-0.42.0 numba-0.59.1 pennylane-0.35.1 pennylane-lightning-0.35.1 quimb-1.7.3 rustworkx-0.14.2 semantic-version-2.10.0 toml-0.10.2 torchmetrics-1.3.2\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-02T16:10:43.550874Z",
     "iopub.status.busy": "2024-04-02T16:10:43.550642Z",
     "iopub.status.idle": "2024-04-02T16:10:47.679639Z",
     "shell.execute_reply": "2024-04-02T16:10:47.678406Z",
     "shell.execute_reply.started": "2024-04-02T16:10:43.550852Z"
    },
    "id": "VN2wD-U7bGse",
    "outputId": "efc73948-0832-402c-eafc-b0e6adce4a54",
    "ExecuteTime": {
     "end_time": "2024-04-07T14:04:40.242061Z",
     "start_time": "2024-04-07T14:04:36.885586Z"
    }
   },
   "source": [
    "# Import packages\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "#np.set_printoptions(threshold=sys.maxsize)\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import seaborn as sns\n",
    "#import jax\n",
    "import time\n",
    "\n",
    "import functools\n",
    "\n",
    "from typing import List, Union, Tuple, Dict, Optional, Any\n",
    "from typing import Callable\n",
    "\n",
    "#jax.config.update(\"jax_enable_x64\", True)\n",
    "#jax.config.update(\"jax_debug_nans\", True)\n",
    "#import jax.numpy as jnp\n",
    "\n",
    "#import optax  # optimization using jax\n",
    "\n",
    "import torch  # https://pytorch.org\n",
    "import torchvision  # https://pytorch.org\n",
    "#torch.set_printoptions(profile=\"full\")\n",
    "#import torch_xla\n",
    "#import torch_xla.core.xla_model as xm\n",
    "\n",
    "\n",
    "\n",
    "#import pennylane as qml\n",
    "#import pennylane.numpy as pnp\n",
    "\n",
    "import os, cv2, itertools # cv2 -- OpenCV\n",
    "import shutil\n",
    "import zipfile\n",
    "%matplotlib inline\n",
    "\n",
    "#from jax.lib import xla_bridge\n",
    "\n",
    "\n",
    "sns.set()\n",
    "\n",
    "seed = 1701\n",
    "rng = np.random.default_rng(seed=seed)\n",
    "#prng = pnp.random.default_rng(seed=seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "#torch.set_default_dtype(torch.double)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "COMPLEX_DTYPE = torch.cfloat #torch.cdouble\n",
    "REAL_DTYPE = torch.float\n",
    "\n",
    "print(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WmQPQuLbSFw"
   },
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-02T16:10:47.680869Z",
     "iopub.status.busy": "2024-04-02T16:10:47.680416Z",
     "iopub.status.idle": "2024-04-02T16:10:47.809475Z",
     "shell.execute_reply": "2024-04-02T16:10:47.808255Z",
     "shell.execute_reply.started": "2024-04-02T16:10:47.680826Z"
    },
    "id": "rUhQUP2dbTja",
    "outputId": "0d3641db-a2ff-4689-8b7e-32e0e8b313d4",
    "ExecuteTime": {
     "end_time": "2024-04-07T14:04:40.634551Z",
     "start_time": "2024-04-07T14:04:40.243349Z"
    }
   },
   "source": [
    "preprocess = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Pad(2),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    #torchvision.transforms.Lambda(lambda x: torch.squeeze(x)),\n",
    "    #torchvision.transforms.Lambda(lambda x: x / torch.trace(x)),\n",
    "    #torchvision.transforms.Lambda(lambda x: (x+torch.t(x))/2)\n",
    "    torchvision.transforms.Normalize((0.5,), (0.5,)),\n",
    "    torchvision.transforms.Lambda(lambda x: x.type(COMPLEX_DTYPE))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    \"MNIST\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=preprocess,\n",
    ")\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    \"MNIST\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=preprocess,\n",
    ")\n",
    "dummy_trainloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=32, shuffle=True\n",
    ")\n",
    "dummy_testloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=32, shuffle=True\n",
    ")\n",
    "\n",
    "dummy_x, dummy_y = next(iter(dummy_trainloader))\n",
    "\n",
    "print(dummy_x.shape)  # 64x32x32\n",
    "print(dummy_y.shape)  # 64\n",
    "print(dummy_y)\n",
    "print(dummy_x[0,0,16])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 32, 32])\n",
      "torch.Size([32])\n",
      "tensor([7, 7, 5, 7, 4, 7, 7, 7, 5, 4, 7, 2, 7, 8, 1, 1, 1, 6, 4, 1, 5, 1, 2, 7,\n",
      "        8, 0, 8, 6, 1, 8, 8, 7])\n",
      "tensor([-1.0000+0.j, -1.0000+0.j, -1.0000+0.j, -1.0000+0.j, -1.0000+0.j, -1.0000+0.j,\n",
      "        -1.0000+0.j, -1.0000+0.j, -1.0000+0.j, -1.0000+0.j, -1.0000+0.j, -1.0000+0.j,\n",
      "        -1.0000+0.j, -1.0000+0.j, -1.0000+0.j, -1.0000+0.j, -1.0000+0.j, -1.0000+0.j,\n",
      "        -1.0000+0.j,  0.2863+0.j,  0.7098+0.j, -0.7333+0.j, -1.0000+0.j, -1.0000+0.j,\n",
      "        -1.0000+0.j, -1.0000+0.j, -1.0000+0.j, -1.0000+0.j, -1.0000+0.j, -1.0000+0.j,\n",
      "        -1.0000+0.j, -1.0000+0.j])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQI8WWY6byQq"
   },
   "source": [
    "# Some Utilities"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-02T16:10:47.812079Z",
     "iopub.status.busy": "2024-04-02T16:10:47.811853Z",
     "iopub.status.idle": "2024-04-02T16:10:49.208648Z",
     "shell.execute_reply": "2024-04-02T16:10:49.207311Z",
     "shell.execute_reply.started": "2024-04-02T16:10:47.812056Z"
    },
    "id": "7B4DTncWbwQl",
    "outputId": "38975b7c-66c4-49f5-e5fd-158e55028cdd",
    "ExecuteTime": {
     "end_time": "2024-04-07T14:04:42.329623Z",
     "start_time": "2024-04-07T14:04:40.635748Z"
    }
   },
   "source": [
    "ket = {\n",
    "    '0':torch.tensor([1.,0.], dtype = COMPLEX_DTYPE, device=device),\n",
    "    '1':torch.tensor([0.,1.], dtype = COMPLEX_DTYPE, device=device),\n",
    "    '+':(torch.tensor([1,0], dtype = COMPLEX_DTYPE, device=device) + torch.tensor([0,1], dtype = COMPLEX_DTYPE, device=device))/torch.sqrt(torch.tensor(2, dtype = COMPLEX_DTYPE, device=device)),\n",
    "    '-':(torch.tensor([1,0], dtype = COMPLEX_DTYPE, device=device) - torch.tensor([0,1], dtype = COMPLEX_DTYPE, device=device))/torch.sqrt(torch.tensor(2, dtype = COMPLEX_DTYPE, device=device))\n",
    "}\n",
    "\n",
    "pauli = {\n",
    "    'I':torch.tensor([[1.,0.],[0.,1.]], dtype = COMPLEX_DTYPE, device=device),\n",
    "    'X':torch.tensor([[0.,1.],[1.,0.]], dtype = COMPLEX_DTYPE, device=device),\n",
    "    'Y':torch.tensor([[0., -1.j],[1.j, 0]], dtype = COMPLEX_DTYPE, device=device),\n",
    "    'Z':torch.tensor([[1.,0.],[0.,-1.]], dtype = COMPLEX_DTYPE, device=device)\n",
    "}\n",
    "\n",
    "def tensor_product(*args):\n",
    "  input_list = [a for a in args]\n",
    "  return functools.reduce(torch.kron, input_list)\n",
    "\n",
    "def multi_qubit_identity(n_qubits:int):\n",
    "  assert n_qubits>0\n",
    "  if n_qubits == 1:\n",
    "    return pauli['I']\n",
    "  else:\n",
    "    return tensor_product(*[pauli['I'] for _ in range(n_qubits)])\n",
    "\n",
    "pauli_words_su4 = {}\n",
    "for key1 in pauli.keys():\n",
    "  for key2 in pauli.keys():\n",
    "    if not (key1==key2 and key1=='I' and key2=='I'):\n",
    "      #print(key1, key2)\n",
    "      #print(pauli[key1])\n",
    "      #print(pauli[key2])\n",
    "      pauli_words_su4[key1+key2] = tensor_product(pauli[key1], pauli[key2])\n",
    "      #print(pauli_words_su4[key1+key2])\n",
    "\n",
    "pauli_words_su8 = {}\n",
    "for key1 in pauli.keys():\n",
    "  for key2 in pauli.keys():\n",
    "    for key3 in pauli.keys():\n",
    "      if not key1+key2+key3 == 'III':\n",
    "        pauli_words_su8[key1+key2+key3] = tensor_product(pauli[key1], pauli[key2], pauli[key3])\n",
    "\n",
    "pauli_words_su16 = {}\n",
    "for key1 in pauli.keys():\n",
    "  for key2 in pauli.keys():\n",
    "    for key3 in pauli.keys():\n",
    "      for key4 in pauli.keys():\n",
    "        if not key1+key2+key3+key4 == 'IIII':\n",
    "          pauli_words_su16[key1+key2+key3+key4] = tensor_product(\n",
    "              pauli[key1],\n",
    "              pauli[key2],\n",
    "              pauli[key3],\n",
    "              pauli[key4]\n",
    "          )\n",
    "\n",
    "pauli_words_su32 = {}\n",
    "for key1 in pauli.keys():\n",
    "  for key2 in pauli.keys():\n",
    "    for key3 in pauli.keys():\n",
    "      for key4 in pauli.keys():\n",
    "        for key5 in pauli.keys():\n",
    "          if not key1+key2+key3+key4+key5 == 'IIIII':\n",
    "            pauli_words_su32[key1+key2+key3+key4+key5] = tensor_product(\n",
    "                pauli[key1],\n",
    "                pauli[key2],\n",
    "                pauli[key3],\n",
    "                pauli[key4],\n",
    "                pauli[key5]\n",
    "            )\n",
    "\n",
    "def su32_op(\n",
    "    params\n",
    "):\n",
    "  dict_values = list(pauli_words_su32.values())\n",
    "  generator = torch.einsum(\"i,ijk->jk\", params, torch.stack(dict_values))\n",
    "  #print(generator.shape)\n",
    "  return torch.matrix_exp(1j*generator)\n",
    "\n",
    "def su4_op(\n",
    "    params\n",
    "):\n",
    "  dict_values = torch.stack(list(pauli_words_su4.values()))\n",
    "  #print(dict_values.shape)\n",
    "  generator = torch.einsum(\"i, ijk -> jk\", params, dict_values)\n",
    "  return torch.linalg.matrix_exp(1.0j*generator)\n",
    "\n",
    "def pauli_dict_func(key):\n",
    "    return pauli[key]\n",
    "\n",
    "def pauli_dict_func_multiple_keys(keys):\n",
    "    return list(map(pauli_dict_func, keys))\n",
    "\n",
    "def pauli_string_tensor_prod(pauli_string:str):\n",
    "    paulis_char = list(pauli_string)\n",
    "    paulis_mat = pauli_dict_func_multiple_keys(paulis_char)\n",
    "    return tensor_product(*paulis_mat)\n",
    "\n",
    "def generate_nqubit_pauli_strings(n_qubits:int):\n",
    "    assert n_qubits>0\n",
    "    pauli_labels = ['I', 'X', 'Y', 'Z']\n",
    "    pauli_strings = []\n",
    "    for labels in itertools.product(pauli_labels, repeat=n_qubits):\n",
    "        pauli_str = \"\".join(labels)\n",
    "        if pauli_str != 'I'*n_qubits:\n",
    "            pauli_strings.append(pauli_str)\n",
    "    return pauli_strings\n",
    "\n",
    "def generate_pauli_tensor_list(pauli_strings:list):\n",
    "    return list(map(pauli_string_tensor_prod, pauli_strings))\n",
    "\n",
    "\n",
    "print(\n",
    "    generate_pauli_tensor_list(generate_nqubit_pauli_strings(2))\n",
    ")\n",
    "\n",
    "\n",
    "#test_params = torch.randn(4**2-1,  device=device).type(COMPLEX_DTYPE)\n",
    "#print(test_params.shape)\n",
    "#test_op = su4_op(test_params)\n",
    "#print(test_op)\n",
    "#print(qml.is_unitary(qml.QubitUnitary(test_op.cpu().numpy(), wires=[0,1]))) # will be false if not torch.cdouble\n",
    "\n",
    "#rx = torch.linalg.matrix_exp(1j*torch.pi*pauli[\"X\"]/2)\n",
    "#print(qml.is_unitary(qml.QubitUnitary(rx.cpu().numpy(), wires=[0])))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n",
      "        [1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
      "        [0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n",
      "        [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j]], device='cuda:0'), tensor([[0.+0.j, 0.-1.j, 0.+0.j, 0.-0.j],\n",
      "        [0.+1.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
      "        [0.+0.j, 0.-0.j, 0.+0.j, 0.-1.j],\n",
      "        [0.+0.j, 0.+0.j, 0.+1.j, 0.+0.j]], device='cuda:0'), tensor([[ 1.+0.j,  0.+0.j,  0.+0.j,  0.+0.j],\n",
      "        [ 0.+0.j, -1.+0.j,  0.+0.j, -0.+0.j],\n",
      "        [ 0.+0.j,  0.+0.j,  1.+0.j,  0.+0.j],\n",
      "        [ 0.+0.j, -0.+0.j,  0.+0.j, -1.+0.j]], device='cuda:0'), tensor([[0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\n",
      "        [0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n",
      "        [1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
      "        [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j]], device='cuda:0'), tensor([[0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n",
      "        [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\n",
      "        [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n",
      "        [1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]], device='cuda:0'), tensor([[0.+0.j, 0.-0.j, 0.+0.j, 0.-1.j],\n",
      "        [0.+0.j, 0.+0.j, 0.+1.j, 0.+0.j],\n",
      "        [0.+0.j, 0.-1.j, 0.+0.j, 0.-0.j],\n",
      "        [0.+1.j, 0.+0.j, 0.+0.j, 0.+0.j]], device='cuda:0'), tensor([[ 0.+0.j,  0.+0.j,  1.+0.j,  0.+0.j],\n",
      "        [ 0.+0.j, -0.+0.j,  0.+0.j, -1.+0.j],\n",
      "        [ 1.+0.j,  0.+0.j,  0.+0.j,  0.+0.j],\n",
      "        [ 0.+0.j, -1.+0.j,  0.+0.j, -0.+0.j]], device='cuda:0'), tensor([[0.+0.j, 0.+0.j, 0.-1.j, 0.-0.j],\n",
      "        [0.+0.j, 0.+0.j, 0.-0.j, 0.-1.j],\n",
      "        [0.+1.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
      "        [0.+0.j, 0.+1.j, 0.+0.j, 0.+0.j]], device='cuda:0'), tensor([[0.+0.j, 0.+0.j, 0.-0.j, 0.-1.j],\n",
      "        [0.+0.j, 0.+0.j, 0.-1.j, 0.-0.j],\n",
      "        [0.+0.j, 0.+1.j, 0.+0.j, 0.+0.j],\n",
      "        [0.+1.j, 0.+0.j, 0.+0.j, 0.+0.j]], device='cuda:0'), tensor([[ 0.+0.j,  0.-0.j,  0.-0.j, -1.+0.j],\n",
      "        [ 0.+0.j,  0.+0.j,  1.-0.j,  0.-0.j],\n",
      "        [ 0.+0.j,  1.-0.j,  0.+0.j,  0.-0.j],\n",
      "        [-1.+0.j,  0.+0.j,  0.+0.j,  0.+0.j]], device='cuda:0'), tensor([[0.+0.j, 0.+0.j, 0.-1.j, 0.-0.j],\n",
      "        [0.+0.j, -0.+0.j, 0.-0.j, 0.+1.j],\n",
      "        [0.+1.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
      "        [0.+0.j, -0.-1.j, 0.+0.j, -0.+0.j]], device='cuda:0'), tensor([[ 1.+0.j,  0.+0.j,  0.+0.j,  0.+0.j],\n",
      "        [ 0.+0.j,  1.+0.j,  0.+0.j,  0.+0.j],\n",
      "        [ 0.+0.j,  0.+0.j, -1.+0.j, -0.+0.j],\n",
      "        [ 0.+0.j,  0.+0.j, -0.+0.j, -1.+0.j]], device='cuda:0'), tensor([[ 0.+0.j,  1.+0.j,  0.+0.j,  0.+0.j],\n",
      "        [ 1.+0.j,  0.+0.j,  0.+0.j,  0.+0.j],\n",
      "        [ 0.+0.j,  0.+0.j, -0.+0.j, -1.+0.j],\n",
      "        [ 0.+0.j,  0.+0.j, -1.+0.j, -0.+0.j]], device='cuda:0'), tensor([[0.+0.j, 0.-1.j, 0.+0.j, 0.-0.j],\n",
      "        [0.+1.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
      "        [0.+0.j, 0.-0.j, -0.+0.j, 0.+1.j],\n",
      "        [0.+0.j, 0.+0.j, -0.-1.j, -0.+0.j]], device='cuda:0'), tensor([[ 1.+0.j,  0.+0.j,  0.+0.j,  0.+0.j],\n",
      "        [ 0.+0.j, -1.+0.j,  0.+0.j, -0.+0.j],\n",
      "        [ 0.+0.j,  0.+0.j, -1.+0.j, -0.+0.j],\n",
      "        [ 0.+0.j, -0.+0.j, -0.+0.j,  1.-0.j]], device='cuda:0')]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T16:10:49.210092Z",
     "iopub.status.busy": "2024-04-02T16:10:49.209878Z",
     "iopub.status.idle": "2024-04-02T16:10:49.219820Z",
     "shell.execute_reply": "2024-04-02T16:10:49.219262Z",
     "shell.execute_reply.started": "2024-04-02T16:10:49.210072Z"
    },
    "id": "Xs0c2F1eBnGc",
    "ExecuteTime": {
     "end_time": "2024-04-07T14:04:42.336581Z",
     "start_time": "2024-04-07T14:04:42.331263Z"
    }
   },
   "source": [
    "def measure_sv(\n",
    "    state,\n",
    "    observable\n",
    "    ):\n",
    "  \"\"\"\n",
    "  Measure a statevector with a Hermitian observable.\n",
    "  Note: No checking Hermitianicity of the observable or whether the observable\n",
    "  has all real eigenvalues or not\n",
    "  \"\"\"\n",
    "  expectation_value = torch.conj(state)@observable@state\n",
    "  return torch.real(expectation_value)\n",
    "\n",
    "def measure_dm(\n",
    "    rho,\n",
    "    observable\n",
    "):\n",
    "  \"\"\"\n",
    "  Measure a density matrix with a Hermitian observable.\n",
    "  Note: No checking Hermitianicity of the observable or whether the observable\n",
    "  has all real eigenvalues or not.\n",
    "  \"\"\"\n",
    "  product = torch.matmul(rho, observable)\n",
    "\n",
    "  # Calculate the trace, which is the sum of diagonal elements\n",
    "  trace = torch.trace(product)\n",
    "\n",
    "  # The expectation value should be real for physical observables\n",
    "  return torch.real(trace)\n",
    "\n",
    "vmap_measure_sv = torch.vmap(measure_sv, in_dims=(None, 0), out_dims=0)\n",
    "vmap_measure_dm = torch.vmap(measure_dm, in_dims=(None, 0), out_dims=0)\n",
    "\n",
    "# assuming the input patch observables (hermitianized) has shape (batchsize,n_patches, c, h, w)\n",
    "# assuming the input set statevectors has shape (c, 2**n)\n",
    "# output should have the shape (batchsize,n_patches, channel)\n",
    "vmap_measure_channel_sv_batched_ob = torch.vmap(measure_sv, in_dims = (-2, -3),out_dims=-1)\n",
    "\n",
    "\n",
    "# assuming the input set desnity matrices has shape (batchsize, n_patches, c, 2**n, 2**n)\n",
    "# output should have the shape (batchsize,n_patches, channel)\n",
    "vmap_measure_channel_dm_batched_ob = torch.vmap(measure_dm, in_dims = (-2, -3),out_dims=-1)\n",
    "\n",
    "\n",
    "def bitstring_to_state(bitstring:str):\n",
    "  \"\"\"\n",
    "  Convert a bit string, like '0101001' or '+-+-101'\n",
    "  to a statevector. Each character in the bitstring must be among\n",
    "  0, 1, + and -\n",
    "  \"\"\"\n",
    "  assert len(bitstring)>0\n",
    "  for c in bitstring:\n",
    "    assert c in ['0', '1', '+', '-']\n",
    "  single_qubit_states = [ket[c] for c in bitstring]\n",
    "  return tensor_product(*single_qubit_states)\n",
    "\n",
    "\n",
    "#test_patch = torch.randn(size=[5, 2, 3, 4,4], dtype = torch.double, device=device).type(torch.cdouble)\n",
    "#test_herm_patch = (torch.einsum(\"...jk->...kj\", test_patch)+test_patch)/2\n",
    "#print(test_herm_patch)\n",
    "#print(\"all patches shape\", test_herm_patch.shape)\n",
    "#test_sv = torch.stack([bitstring_to_state('++')]*3, axis = 0)\n",
    "#print(test_sv)\n",
    "#print(\"all sv shape\", test_sv.shape)\n",
    "#res = vmap_measure_channel_sv_batched_ob(test_sv, test_herm_patch)\n",
    "#print(res)\n",
    "#print(\"res shape\",res.shape)\n",
    "\n",
    "#for batchid in range(test_patch.shape[0]):\n",
    "#  batchitem = test_patch[batchid]\n",
    "#  for patch_idx in range(batchitem.shape[0]):\n",
    "#    patch = batchitem[patch_idx]\n",
    "#    for ch_idx in range(patch.shape[0]):\n",
    "#      print(f\"batchid={batchid}; patchid = {patch_idx}; chid = {ch_idx}\")\n",
    "#      ch = patch[ch_idx]\n",
    "#      #print(ch.shape)\n",
    "#      sv_ch = test_sv[ch_idx]\n",
    "#      #print(sv_ch.shape)\n",
    "#      print(measure_sv(sv_ch, ch))\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFZqT6bpElaL"
   },
   "source": [
    "# Flipped Quanvolution Kernel\n",
    "\n",
    "First, let's define the function to extract patches for a single kernel."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T16:10:49.221071Z",
     "iopub.status.busy": "2024-04-02T16:10:49.220885Z",
     "iopub.status.idle": "2024-04-02T16:10:49.226832Z",
     "shell.execute_reply": "2024-04-02T16:10:49.226163Z",
     "shell.execute_reply.started": "2024-04-02T16:10:49.221053Z"
    },
    "id": "He4HdMRHC7T6",
    "ExecuteTime": {
     "end_time": "2024-04-07T14:04:42.387023Z",
     "start_time": "2024-04-07T14:04:42.337635Z"
    }
   },
   "source": [
    "def extract_patches(image, patch_size, stride, padding=None):\n",
    "    \"\"\"\n",
    "    Extracts patches from an image with multiple input channels and optional custom padding.\n",
    "\n",
    "    Args:\n",
    "        image (torch.Tensor): Input image tensor of shape (in_channels, height, width).\n",
    "        patch_size (int): Size of the square patches to extract.\n",
    "        stride (int): Stride between patches.\n",
    "        padding (tuple): Padding value(s) for each dimension.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Tensor of extracted patches of shape (num_patches, in_channels, patch_size, patch_size).\n",
    "    \"\"\"\n",
    "    in_channels, height, width = image.shape[-3], image.shape[-2], image.shape[-1]\n",
    "    pad_l, pad_r, pad_t, pad_b = padding if padding is not None else (0,0,0,0)\n",
    "\n",
    "    if padding is not None:\n",
    "        image = torch.nn.functional.pad(image, (pad_l, pad_r, pad_t, pad_b), mode='constant')\n",
    "    else:\n",
    "        image = image\n",
    "\n",
    "    height, width = image.shape[-2],  image.shape[-1]\n",
    "    num_patches_h = (height - patch_size) // stride + 1\n",
    "    num_patches_w = (width - patch_size) // stride + 1\n",
    "\n",
    "    patches = []\n",
    "    for i in range(num_patches_h):\n",
    "        for j in range(num_patches_w):\n",
    "            patch = image[..., i*stride:i*stride+patch_size, j*stride:j*stride+patch_size]\n",
    "            patches.append(patch)\n",
    "\n",
    "    patches = torch.stack(patches, dim=-4)\n",
    "    return patches # has shape (batchsize, n_patches, channel, h, w)\n",
    "\n",
    "\n",
    "#single_img = torch.stack([torch.arange(32*32*1,dtype = torch.double, device=device).reshape((32,32)).type(torch.cdouble)]*3)\n",
    "\n",
    "#test_img = torch.stack([single_img]*2)\n",
    "#print(test_img[0][...,:4,:4])\n",
    "#patches = extract_patches(test_img, patch_size=4, stride=2,padding=(0,0,0,0))\n",
    "#print(patches.shape)\n",
    "#print(patches[0].shape)\n",
    "#print(patches[0][0])\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hRqflooEqKN"
   },
   "source": [
    "## A Three-by-Three Quanv Kernel Function\n",
    "\n",
    "For 3 by 3 patches, we only need a 2-qubit parameterised state, generated by the SU4 gate applied to the $|00\\rangle$ state. The first thing to do is to pad the 3 by 3 patches to 4 by 4. However, for input with size\n",
    "\n",
    "$$\n",
    "D_1\\times H_1 \\times W_1\n",
    "$$\n",
    "\n",
    "where $D_1$ is the number of input channels, we will need $D_1$ different two-qubit states, generated by $D_1$ different parameterised circuits. These circuits will produce $D_1$ expectation values. Suppose each circuit is parameterised by $\\theta_i, i\\in \\{1,2,\\cdots, D_1\\}$, the parameterised (pure) state can be written as\n",
    "\n",
    "$$\n",
    "|\\psi (\\theta_i)⟩ = SU4(\\theta_i)|00⟩\n",
    "$$\n",
    "\n",
    "For a channel $M_i$ of patch $M$ with shape $4\\times 4$, the expectation value is calculated by\n",
    "\n",
    "$$\n",
    "⟨\\psi(\\theta_i)|\\left(\\frac{M_i+M^T_i}{2}\\right)|\\psi(\\theta_i)⟩\n",
    "$$\n",
    "\n",
    "Then, a single pixel value of the output channel corresponding this single kernel is\n",
    "\n",
    "$$\n",
    "\\frac{1}{D_1}\\sum_{i=1}^{D_1}⟨\\psi(\\theta_i)|\\left(\\frac{M_i+M^T_i}{2}\\right)|\\psi(\\theta_i)⟩\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T16:10:49.227850Z",
     "iopub.status.busy": "2024-04-02T16:10:49.227670Z",
     "iopub.status.idle": "2024-04-02T16:10:49.233341Z",
     "shell.execute_reply": "2024-04-02T16:10:49.232708Z",
     "shell.execute_reply.started": "2024-04-02T16:10:49.227837Z"
    },
    "id": "Yzn4KEt5ErG7",
    "ExecuteTime": {
     "end_time": "2024-04-07T14:04:42.437834Z",
     "start_time": "2024-04-07T14:04:42.389346Z"
    }
   },
   "source": [
    "def generate_2q_param_state(theta):\n",
    "  state = bitstring_to_state('00')\n",
    "  state = torch.matmul(su4_op(theta), state)\n",
    "  return state\n",
    "\n",
    "vmap_generate_2q_param_state = torch.vmap(generate_2q_param_state, in_dims=0, out_dims = 0)\n",
    "\n",
    "def single_kernel_op_over_batched_patches(thetas, patch):\n",
    "  # patch has shape (c_in, h, w)\n",
    "  # thetas has shape (c_in, 4^2-1) for SU4 gates\n",
    "  n_theta = thetas.shape[-2]\n",
    "  n_channel = patch.shape[-3]\n",
    "  assert n_theta == n_channel, \"Thetas and patch must have the same number of channels.\"\n",
    "  states = vmap_generate_2q_param_state(thetas)\n",
    "  #print(\"States shape\", states.shape)\n",
    "  patch = torch.nn.functional.pad(patch, (0, 1, 0, 1), mode='constant')\n",
    "  patch_t = torch.einsum(\"...jk->...kj\", patch)\n",
    "  herm_patch = (patch_t+patch)/2 # has dim (batchsize, num_patches, c, h, w)\n",
    "  #print(\"Herm patch shape\", herm_patch.shape)\n",
    "  channel_out = vmap_measure_channel_sv_batched_ob(states, herm_patch) # has dim (batchsize,n_patches, c)\n",
    "  return torch.sum(channel_out, axis = -1)/n_theta # has dim (batchszie, n_patches)\n",
    "\n",
    "\n",
    "#test_params = torch.randn((1,4**2-1), dtype = torch.double, device=device).type(torch.cdouble)\n",
    "#test_img = dummy_x.to(device)#.type(torch.cdouble)\n",
    "#print(test_img.shape)\n",
    "#test_patches = extract_patches(test_img, patch_size=3, stride=1,padding=(1,1,1,1))\n",
    "#print(test_patches.shape)\n",
    "#print(test_params.shape)\n",
    "#print(vmap_generate_2q_param_state(test_params))\n",
    "#test_out = single_kernel_op_over_batched_patches(test_params, test_patches)\n",
    "#print(test_out.shape)\n",
    "#h = (32-3+1*2)//1 +1\n",
    "#h**2\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4BXEKd8I67_"
   },
   "source": [
    "## Multiple Output Channels"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T16:10:49.234207Z",
     "iopub.status.busy": "2024-04-02T16:10:49.234022Z",
     "iopub.status.idle": "2024-04-02T16:10:49.237565Z",
     "shell.execute_reply": "2024-04-02T16:10:49.237013Z",
     "shell.execute_reply.started": "2024-04-02T16:10:49.234191Z"
    },
    "id": "72vkHV_BI80l",
    "ExecuteTime": {
     "end_time": "2024-04-07T14:04:42.477923Z",
     "start_time": "2024-04-07T14:04:42.438981Z"
    }
   },
   "source": [
    "# For multiple channel output\n",
    "# parameter has shape (c_out, c_in, 4**2-1) for SU4 gates\n",
    "vmap_vmap_single_kernel_op_through_extracted_patches = torch.vmap(single_kernel_op_over_batched_patches, in_dims=(0, None), out_dims=-2) # output has dim (batchsize, c_out, n_patches)\n",
    "\n",
    "#c_in = 1\n",
    "#c_out = 2\n",
    "\n",
    "#test_params2 = torch.randn((c_out, c_in,4**2-1), dtype = torch.double, device=device).type(torch.cdouble)\n",
    "#test_out2 = vmap_vmap_single_kernel_op_through_extracted_patches(test_params2, test_patches)\n",
    "#print(test_out2.shape)\n",
    "#test_out_2_features = test_out2.reshape((-1,c_out, 32, 32))\n",
    "#print(test_out_2_features.shape)\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuZ6G5-sKK_J"
   },
   "source": [
    "## Pytorch Module for Three-by-Three Flipped Quanv"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T16:10:49.238726Z",
     "iopub.status.busy": "2024-04-02T16:10:49.238539Z",
     "iopub.status.idle": "2024-04-02T16:10:49.246127Z",
     "shell.execute_reply": "2024-04-02T16:10:49.245545Z",
     "shell.execute_reply.started": "2024-04-02T16:10:49.238711Z"
    },
    "id": "Gww_XdJ5KPJt",
    "ExecuteTime": {
     "end_time": "2024-04-07T14:04:42.524052Z",
     "start_time": "2024-04-07T14:04:42.479076Z"
    }
   },
   "source": [
    "class FlippedQuanv3x3(torch.nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, stride, padding):\n",
    "    super(FlippedQuanv3x3, self).__init__()\n",
    "    self.in_channels = in_channels\n",
    "    self.out_channels = out_channels\n",
    "    self.stride = stride\n",
    "    self.padding = padding\n",
    "    self.pad_l, self.pad_r, self.pad_t, self.pad_b = padding if padding is not None else (0,0,0,0)\n",
    "    self.pad = (self.pad_l, self.pad_r, self.pad_t, self.pad_b)\n",
    "    self.weight= torch.nn.Parameter(torch.randn((out_channels, in_channels, 4**2-1)).type(COMPLEX_DTYPE))\n",
    "    self.bias = torch.nn.Parameter(torch.randn((out_channels, 1)).type(COMPLEX_DTYPE))\n",
    "\n",
    "  def forward(self, x):\n",
    "    # x has shape (batchsize ,c_in, h, w)\n",
    "    # weight has shape (c_out, c_in, 15)\n",
    "    # bias has shape (c_out, 1)\n",
    "    x = x.type(COMPLEX_DTYPE)\n",
    "    c_in, h_in, w_in = x.shape[-3], x.shape[-2], x.shape[-1]\n",
    "    patches = extract_patches(x, patch_size=3, stride=self.stride, padding=self.pad)\n",
    "    h_out = (h_in-3+(self.pad_t+self.pad_b))//self.stride +1\n",
    "    w_out = (w_in-3+(self.pad_l+self.pad_r))//self.stride +1\n",
    "\n",
    "    #print(self.weight.shape)\n",
    "    #print(patches.shape)\n",
    "\n",
    "    out = vmap_vmap_single_kernel_op_through_extracted_patches(self.weight, patches)\n",
    "\n",
    "\n",
    "    out = out + self.bias\n",
    "    return out.reshape((-1,self.out_channels, h_out, w_out)).type(REAL_DTYPE)\n",
    "\n",
    "  def extra_repr(self) -> str:\n",
    "        return f'in_channels={self.in_channels}, out_channels={self.out_channels}, stride={self.stride}, padding={self.padding}'\n",
    "\n",
    "#test_module = FlippedQuanv3x3(in_channels=1, out_channels=2, stride=1, padding=(1,1,1,1)).to(device)\n",
    "#print(dummy_x.shape)\n",
    "#test_out = test_module(dummy_x.to(device))\n",
    "#print(test_out.shape)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5jY9sQZ7Ynla"
   },
   "source": [
    "# Linear Layer\n",
    "\n",
    "For input dimension $D$, the quantum linear layer is a $n = \\lceil \\log_4(D+1)⌉$-qubit quantum circuit. Both the data encoding and parameterised circuit is achieved via the $SU(2^n)$ unitary."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T16:10:49.248151Z",
     "iopub.status.busy": "2024-04-02T16:10:49.247958Z",
     "iopub.status.idle": "2024-04-02T16:10:50.659602Z",
     "shell.execute_reply": "2024-04-02T16:10:50.658944Z",
     "shell.execute_reply.started": "2024-04-02T16:10:49.248134Z"
    },
    "id": "AXxNIObFYnPW",
    "ExecuteTime": {
     "end_time": "2024-04-07T14:04:44.126106Z",
     "start_time": "2024-04-07T14:04:42.525306Z"
    }
   },
   "source": [
    "def data_encode_unitary(padded_data, t):\n",
    "  original_dim = padded_data.shape[-1]\n",
    "  new_dim = torch.sqrt(torch.tensor(original_dim)).type(torch.int)\n",
    "  data = torch.reshape(padded_data, (new_dim, new_dim))\n",
    "  generator = (data + torch.einsum(\"...jk->...kj\", data))/2\n",
    "  return torch.linalg.matrix_exp(1.0j*generator*t)\n",
    "\n",
    "def su_n(params, pauli_string_tensor_list):\n",
    "  # params has dim 4**n-1\n",
    "  paulis = torch.stack(pauli_string_tensor_list)\n",
    "  generator = torch.einsum(\"i,ijk->jk\", params, paulis)\n",
    "  return torch.linalg.matrix_exp(1.0j*generator)\n",
    "\n",
    "def linear_layer_func(padded_data, params, pauli_string_tensor_list, observables, n_qubits):\n",
    "  n_rep = params.shape[0]\n",
    "  state = bitstring_to_state(\"+\"*n_qubits)\n",
    "  for i in range(n_rep):\n",
    "    data_unitary = data_encode_unitary(padded_data, 1/n_rep)\n",
    "    #print(data_unitary.shape)\n",
    "    #print(state.shape)\n",
    "    state = torch.matmul(\n",
    "      data_unitary,\n",
    "      state\n",
    "    )\n",
    "    sun_gate = su_n(params[i], pauli_string_tensor_list)\n",
    "    #print(sun_gate.shape)\n",
    "    state = torch.matmul(\n",
    "      sun_gate,\n",
    "      state\n",
    "    )\n",
    "  return vmap_measure_sv(state, observables)\n",
    "\n",
    "test_params = torch.randn((3, 4**2-1),device=device).type(COMPLEX_DTYPE)\n",
    "test_data = torch.randn(4**2, device=device).type(COMPLEX_DTYPE)\n",
    "test_obs = torch.stack([torch.outer(bitstring_to_state('00'), bitstring_to_state('00')),\n",
    "                        torch.outer(bitstring_to_state('01'), bitstring_to_state('01')),\n",
    "                        torch.outer(bitstring_to_state('10'), bitstring_to_state('10')),\n",
    "                         torch.outer(bitstring_to_state('11'), bitstring_to_state('11'))])\n",
    "test_pauli_string_tensor_list = generate_pauli_tensor_list(generate_nqubit_pauli_strings(2))\n",
    "\n",
    "\n",
    "test_out = linear_layer_func(test_data, test_params, test_pauli_string_tensor_list, test_obs, 2)\n",
    "print(test_out)\n",
    "print(torch.sum(test_out))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0847, 0.6649, 0.0675, 0.1829], device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T16:10:50.660727Z",
     "iopub.status.busy": "2024-04-02T16:10:50.660497Z",
     "iopub.status.idle": "2024-04-02T16:10:50.673338Z",
     "shell.execute_reply": "2024-04-02T16:10:50.672720Z",
     "shell.execute_reply.started": "2024-04-02T16:10:50.660708Z"
    },
    "id": "2F4_SBgIYnMv",
    "ExecuteTime": {
     "end_time": "2024-04-07T14:04:44.148477Z",
     "start_time": "2024-04-07T14:04:44.128663Z"
    }
   },
   "source": [
    "vmap_batch_linear_layer_func = torch.vmap(linear_layer_func, in_dims=(0, None, None, None, None), out_dims=0)\n",
    "\n",
    "test_data = torch.randn((3, 4**2), device=device).type(COMPLEX_DTYPE)\n",
    "test_out = vmap_batch_linear_layer_func(test_data, test_params, test_pauli_string_tensor_list, test_obs, 2)\n",
    "print(test_out)\n",
    "print(torch.sum(test_out))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3414, 0.4328, 0.0295, 0.1964],\n",
      "        [0.4175, 0.1313, 0.2182, 0.2330],\n",
      "        [0.1889, 0.5187, 0.1613, 0.1311]], device='cuda:0')\n",
      "tensor(3.0000, device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ryROGtnC_3po"
   },
   "source": [
    "## PyTorch Module for the Quantum Version of Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T16:10:50.674334Z",
     "iopub.status.busy": "2024-04-02T16:10:50.674133Z",
     "iopub.status.idle": "2024-04-02T16:10:50.704785Z",
     "shell.execute_reply": "2024-04-02T16:10:50.704215Z",
     "shell.execute_reply.started": "2024-04-02T16:10:50.674316Z"
    },
    "id": "RlTC952w_8VW",
    "ExecuteTime": {
     "end_time": "2024-04-07T14:04:44.214024Z",
     "start_time": "2024-04-07T14:04:44.150350Z"
    }
   },
   "source": [
    "class DataReUploadingLinear(torch.nn.Module):\n",
    "  def __init__(self, in_dim, out_dim, n_qubits, n_reps):\n",
    "    super(DataReUploadingLinear, self).__init__()\n",
    "    assert 2**n_qubits >= out_dim\n",
    "    assert 4**n_qubits >= in_dim\n",
    "    self.in_dim = in_dim\n",
    "    self.out_dim = out_dim\n",
    "    self.n_qubits = n_qubits\n",
    "    self.n_reps = n_reps\n",
    "    self.pauli_string_tensor_list = generate_pauli_tensor_list(generate_nqubit_pauli_strings(n_qubits))\n",
    "    self.param_dim = 4**n_qubits-1\n",
    "    self.params = torch.nn.Parameter(torch.randn((self.n_reps,self.param_dim)).type(COMPLEX_DTYPE))\n",
    "    self.bias = torch.nn.Parameter(torch.randn(out_dim).type(REAL_DTYPE))\n",
    "    self.observables = self.generate_observables()\n",
    "    self.pad_size = 4**n_qubits-self.in_dim\n",
    "\n",
    "  def forward(self, x):\n",
    "    # x has size (batchsize, in_dim)\n",
    "    # pad x\n",
    "    x = torch.nn.functional.pad(x, (0, self.pad_size)).type(COMPLEX_DTYPE)\n",
    "    out = vmap_batch_linear_layer_func(x, self.params, self.pauli_string_tensor_list, self.observables, self.n_qubits)\n",
    "    out = out.type(REAL_DTYPE) + self.bias\n",
    "    return out\n",
    "\n",
    "  def generate_observables(self):\n",
    "    observables = []\n",
    "    for i in range(self.out_dim):\n",
    "      temp_bitstring = '{0:b}'.format(i).zfill(self.n_qubits)\n",
    "      ob = torch.outer(bitstring_to_state(temp_bitstring), bitstring_to_state(temp_bitstring))\n",
    "      observables.append(ob)\n",
    "    return torch.stack(observables)\n",
    "\n",
    "  def extra_repr(self) -> str:\n",
    "        return f'in_dim={self.in_dim}, out_dim={self.out_dim}, n_qubits={self.n_qubits}, n_reps={self.n_reps}'\n",
    "\n",
    "test_linear_module = DataReUploadingLinear(in_dim=45, out_dim=6, n_qubits=3, n_reps = 10).to(device)\n",
    "test_data = torch.randn((16, 45), device=device).type(COMPLEX_DTYPE)\n",
    "print(test_data.shape)\n",
    "test_out = test_linear_module(test_data.to(device))\n",
    "print(test_out.shape)\n",
    "print(test_linear_module)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 45])\n",
      "torch.Size([16, 6])\n",
      "DataReUploadingLinear(in_dim=45, out_dim=6, n_qubits=3, n_reps=10)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1yumZTjDVu63"
   },
   "source": [
    "# Replacing Classical Layers with Quantum Layers\n",
    "\n",
    "Let's replace `Conv2d` with `FlippedQuanv3x3`, and `Linear` with `QuantLinear`,"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-02T16:10:50.705862Z",
     "iopub.status.busy": "2024-04-02T16:10:50.705674Z",
     "iopub.status.idle": "2024-04-02T16:10:52.137407Z",
     "shell.execute_reply": "2024-04-02T16:10:52.136754Z",
     "shell.execute_reply.started": "2024-04-02T16:10:50.705842Z"
    },
    "id": "W4RC5ou-VzbE",
    "outputId": "9eb0b35d-ed18-431b-8a53-ba5216d3fd06",
    "ExecuteTime": {
     "end_time": "2024-04-07T14:04:46.507149Z",
     "start_time": "2024-04-07T14:04:44.217336Z"
    }
   },
   "source": [
    "class HybridNet(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(HybridNet, self).__init__()\n",
    "\n",
    "    self.layers = torch.nn.Sequential(\n",
    "        FlippedQuanv3x3(in_channels=1, out_channels=32, stride=1, padding=None), # 32->30\n",
    "        #torch.nn.ReLU(),\n",
    "        #torch.nn.MaxPool2d(kernel_size=2, stride=1),\n",
    "        FlippedQuanv3x3(in_channels=32, out_channels=16, stride=1, padding=None), # 30->28\n",
    "        #torch.nn.ReLU(),\n",
    "        #torch.nn.MaxPool2d(kernel_size=2, stride=1),\n",
    "        torch.nn.Flatten(),\n",
    "        DataReUploadingLinear(16*28*28, 10, 7, 10)\n",
    "        #torch.nn.Linear(32*14*14, 10).type(REAL_DTYPE)\n",
    "    )\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    logits = self.layers(x)\n",
    "    return logits\n",
    "\n",
    "\n",
    "net = HybridNet().to(device)\n",
    "test_img = dummy_x.to(device)\n",
    "print(test_img.shape)\n",
    "print(net)\n",
    "test_out = net(test_img)\n",
    "print(test_out.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 32, 32])\n",
      "HybridNet(\n",
      "  (layers): Sequential(\n",
      "    (0): FlippedQuanv3x3(in_channels=1, out_channels=32, stride=1, padding=None)\n",
      "    (1): FlippedQuanv3x3(in_channels=32, out_channels=16, stride=1, padding=None)\n",
      "    (2): Flatten(start_dim=1, end_dim=-1)\n",
      "    (3): DataReUploadingLinear(in_dim=12544, out_dim=10, n_qubits=7, n_reps=10)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36/1953195815.py:85: UserWarning: There is a performance drop because we have not yet implemented the batching rule for aten::matrix_exp. Please file us an issue on GitHub so that we can prioritize its implementation. (Triggered internally at ../aten/src/ATen/functorch/BatchedFallback.cpp:82.)\n",
      "  return torch.linalg.matrix_exp(1.0j*generator)\n",
      "/tmp/ipykernel_36/300606786.py:30: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at ../aten/src/ATen/native/Copy.cpp:301.)\n",
      "  return out.reshape((-1,self.out_channels, h_out, w_out)).type(REAL_DTYPE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10])\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "execution": {
     "iopub.execute_input": "2024-04-02T16:10:52.140051Z",
     "iopub.status.busy": "2024-04-02T16:10:52.139814Z",
     "iopub.status.idle": "2024-04-03T00:55:24.432378Z",
     "shell.execute_reply": "2024-04-03T00:55:24.431260Z",
     "shell.execute_reply.started": "2024-04-02T16:10:52.140031Z"
    },
    "id": "x4ZY59q1WS4x",
    "outputId": "6532aea1-47a3-49f3-fe36-b774aee1905f",
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-04-07T14:04:46.508838Z"
    }
   },
   "source": [
    "import torchmetrics\n",
    "#criterion = torch.nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "#accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
    "\n",
    "BATCH_SIZE = 200\n",
    "LEARNING_RATE = 3e-4\n",
    "STEPS = 100\n",
    "PRINT_EVERY_PERCENT = 0.1\n",
    "\n",
    "def train(\n",
    "    model,\n",
    "    optim=torch.optim.SGD,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    accuracy = torchmetrics.Accuracy,\n",
    "    steps = 100,\n",
    "    print_every_percent=0.1,\n",
    "    batchsize = 100,\n",
    "    lr = 0.001,\n",
    "    device=torch.device(\"cpu\")\n",
    "):\n",
    "  trainloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batchsize, shuffle=True\n",
    "  )\n",
    "  testloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batchsize, shuffle=True\n",
    "  )\n",
    "\n",
    "  n_train_batches = len(trainloader)\n",
    "  n_test_batches = len(testloader)\n",
    "  print_every_train_batch = int(n_train_batches*print_every_percent)\n",
    "  print_every_test_batch = int(n_test_batches*print_every_percent)\n",
    "\n",
    "  print(f\"Number of train batches = {n_train_batches}, Number of test batches = {n_test_batches}\")\n",
    "  print(f\"Print every train batch = {print_every_train_batch}, Print every test batch = {print_every_test_batch}\")\n",
    "\n",
    "  model.to(device)\n",
    "  optimizer = optim(model.parameters(), lr=lr, momentum=0.9)\n",
    "  loss = criterion()\n",
    "  acc_func = accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "  step_train_losses = []\n",
    "  step_test_losses = []\n",
    "  step_train_accs = []\n",
    "  step_test_accs = []\n",
    "  for i in range(steps):\n",
    "    step_start = time.time()\n",
    "    batch_train_loss = []\n",
    "    batch_train_acc = []\n",
    "    batch_test_loss = []\n",
    "    batch_test_acc = []\n",
    "    # train\n",
    "    model.train()\n",
    "    for batchid, (images, labels) in enumerate(trainloader):\n",
    "      batch_start = time.time()\n",
    "      images, labels = images.to(device), labels.to(device)\n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(images)\n",
    "      train_loss = loss(outputs, labels)\n",
    "      train_loss.backward()\n",
    "      optimizer.step()\n",
    "      train_acc = acc_func(outputs, labels)\n",
    "      batch_train_loss.append(train_loss.item())\n",
    "      batch_train_acc.append(train_acc.item())\n",
    "      batch_finish = time.time()\n",
    "\n",
    "      if (batchid) % print_every_train_batch == 0:\n",
    "        print(f\"Training at step={i}, batch={batchid}, train loss = {train_loss.item()}, train acc = {train_acc.item()}, time = {batch_finish-batch_start}\")\n",
    "\n",
    "    # eval\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      for batchid, (images, labels) in enumerate(testloader):\n",
    "        batch_start = time.time()\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        test_loss = loss(outputs, labels)\n",
    "        test_acc = acc_func(outputs, labels)\n",
    "        batch_test_loss.append(test_loss.item())\n",
    "        batch_test_acc.append(test_acc.item())\n",
    "        batch_finish = time.time()\n",
    "        if (batchid) % print_every_test_batch == 0:\n",
    "          print(f\"Testing at step={i}, batch={batchid}, test loss = {test_loss.item()}, test acc = {test_acc.item()}, time = {batch_finish-batch_start}\")\n",
    "\n",
    "    step_train_losses.append(np.mean(batch_train_loss))\n",
    "    step_test_losses.append(np.mean(batch_test_loss))\n",
    "    step_train_accs.append(np.mean(batch_train_acc))\n",
    "    step_test_accs.append(np.mean(batch_test_acc))\n",
    "    step_finish = time.time()\n",
    "    print(f\"Step {i} finished in {step_finish-step_start}, Train loss = {step_train_losses[-1]}, Test loss = {step_test_losses[-1]}; Train Acc = {step_train_accs[-1]}, Test Acc = {step_test_accs[-1]}\")\n",
    "\n",
    "  return step_train_losses, step_test_losses, step_train_accs, step_test_accs\n",
    "\n",
    "train_losses, test_losses, train_accs, test_accs = train(net,\n",
    "                                                        optim=torch.optim.SGD,\n",
    "                                                        criterion=torch.nn.CrossEntropyLoss,\n",
    "                                                        accuracy = torchmetrics.Accuracy,\n",
    "                                                        steps = STEPS,\n",
    "                                                        print_every_percent=PRINT_EVERY_PERCENT,\n",
    "                                                        batchsize = BATCH_SIZE,\n",
    "                                                        lr = LEARNING_RATE,\n",
    "                                                        device=device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train batches = 300, Number of test batches = 50\n",
      "Print every train batch = 30, Print every test batch = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36/1953195815.py:85: UserWarning: There is a performance drop because we have not yet implemented the batching rule for aten::matrix_exp. Please file us an issue on GitHub so that we can prioritize its implementation. (Triggered internally at ../aten/src/ATen/functorch/BatchedFallback.cpp:82.)\n",
      "  return torch.linalg.matrix_exp(1.0j*generator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at step=0, batch=0, train loss = 2.6262035369873047, train acc = 0.10000000149011612, time = 0.9974138736724854\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T00:55:24.433537Z",
     "iopub.status.busy": "2024-04-03T00:55:24.433325Z",
     "iopub.status.idle": "2024-04-03T00:55:24.787803Z",
     "shell.execute_reply": "2024-04-03T00:55:24.787177Z",
     "shell.execute_reply.started": "2024-04-03T00:55:24.433517Z"
    },
    "id": "U0Q0vFm7B6cg",
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# plot\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot the losses\n",
    "ax1.plot(train_losses, label='Train Loss')\n",
    "ax1.plot(test_losses, label='Test Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Loss vs. Epoch')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot the accuracies\n",
    "ax2.plot(train_accs, label='Train Accuracy')\n",
    "ax2.plot(test_accs, label='Test Accuracy')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Accuracy vs. Epoch')\n",
    "ax2.legend()\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"2-mnist_full_repacement.pdf\")\n",
    "# Display the plots\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "\n",
    "res_dict = {\n",
    "    \"train_losses\": train_losses,\n",
    "    \"test_losses\": test_losses,\n",
    "    \"train_accs\": train_accs,\n",
    "    \"test_accs\": test_accs\n",
    "}\n",
    "\n",
    "with open(\"2-mnist_full_replacement.json\", \"w\") as f:\n",
    "    json.dump(res_dict, f)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
