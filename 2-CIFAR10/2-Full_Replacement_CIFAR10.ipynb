{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-03T08:22:52.948872Z",
     "iopub.status.busy": "2024-04-03T08:22:52.948409Z",
     "iopub.status.idle": "2024-04-03T08:24:31.832368Z",
     "shell.execute_reply": "2024-04-03T08:24:31.831751Z",
     "shell.execute_reply.started": "2024-04-03T08:22:52.948838Z"
    },
    "id": "5ebnFsErY0EM",
    "outputId": "e8932b66-715c-467f-912a-8b449c518214",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.17.2)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.9/dist-packages (2.2.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.9/dist-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from torch) (2023.1.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.9/dist-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.9/dist-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.9/dist-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.9/dist-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.9/dist-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.9/dist-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.9/dist-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.9/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.23.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pennylane in /usr/local/lib/python3.9/dist-packages (0.35.1)\n",
      "Requirement already satisfied: cotengra in /usr/local/lib/python3.9/dist-packages (0.5.6)\n",
      "Requirement already satisfied: quimb in /usr/local/lib/python3.9/dist-packages (1.7.3)\n",
      "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.9/dist-packages (1.3.2)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.9/dist-packages (from pennylane) (0.10.2)\n",
      "Requirement already satisfied: autoray>=0.6.1 in /usr/local/lib/python3.9/dist-packages (from pennylane) (0.6.9)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from pennylane) (1.23.4)\n",
      "Requirement already satisfied: semantic-version>=2.7 in /usr/local/lib/python3.9/dist-packages (from pennylane) (2.10.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from pennylane) (2.28.2)\n",
      "Requirement already satisfied: cachetools in /usr/local/lib/python3.9/dist-packages (from pennylane) (5.3.0)\n",
      "Requirement already satisfied: autograd in /usr/local/lib/python3.9/dist-packages (from pennylane) (1.6.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from pennylane) (4.11.0)\n",
      "Requirement already satisfied: rustworkx in /usr/local/lib/python3.9/dist-packages (from pennylane) (0.14.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from pennylane) (3.0)\n",
      "Requirement already satisfied: pennylane-lightning>=0.35 in /usr/local/lib/python3.9/dist-packages (from pennylane) (0.35.1)\n",
      "Requirement already satisfied: appdirs in /usr/local/lib/python3.9/dist-packages (from pennylane) (1.4.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from pennylane) (1.9.2)\n",
      "Requirement already satisfied: psutil>=4.3.1 in /usr/local/lib/python3.9/dist-packages (from quimb) (5.9.4)\n",
      "Requirement already satisfied: numba>=0.39 in /usr/local/lib/python3.9/dist-packages (from quimb) (0.59.1)\n",
      "Requirement already satisfied: tqdm>=4 in /usr/local/lib/python3.9/dist-packages (from quimb) (4.64.1)\n",
      "Requirement already satisfied: cytoolz>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from quimb) (0.12.3)\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (23.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (0.11.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (2.2.2)\n",
      "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from cytoolz>=0.8.0->quimb) (0.12.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (66.1.1)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba>=0.39->quimb) (0.42.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (2.19.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (2023.1.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (11.4.5.107)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (2.2.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (11.0.2.54)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.10.0->torchmetrics) (3.9.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.9/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics) (12.4.127)\n",
      "Requirement already satisfied: future>=0.15.2 in /usr/lib/python3/dist-packages (from autograd->pennylane) (0.18.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->pennylane) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->pennylane) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->pennylane) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->pennylane) (1.26.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install packages\n",
    "!pip install torch torchvision torchaudio --upgrade\n",
    "!pip install pennylane cotengra quimb torchmetrics --upgrade\n",
    "#!pip install -U \"jax[cuda12_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-03T08:25:45.093069Z",
     "iopub.status.busy": "2024-04-03T08:25:45.092790Z",
     "iopub.status.idle": "2024-04-03T08:26:54.096113Z",
     "shell.execute_reply": "2024-04-03T08:26:54.095258Z",
     "shell.execute_reply.started": "2024-04-03T08:25:45.093044Z"
    },
    "id": "VN2wD-U7bGse",
    "outputId": "efc73948-0832-402c-eafc-b0e6adce4a54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "#np.set_printoptions(threshold=sys.maxsize)\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import seaborn as sns\n",
    "#import jax\n",
    "import time\n",
    "\n",
    "import functools\n",
    "\n",
    "from typing import List, Union, Tuple, Dict, Optional, Any\n",
    "from typing import Callable\n",
    "\n",
    "#jax.config.update(\"jax_enable_x64\", True)\n",
    "#jax.config.update(\"jax_debug_nans\", True)\n",
    "#import jax.numpy as jnp\n",
    "\n",
    "#import optax  # optimization using jax\n",
    "\n",
    "import torch  # https://pytorch.org\n",
    "import torchvision  # https://pytorch.org\n",
    "#torch.set_printoptions(profile=\"full\")\n",
    "#import torch_xla\n",
    "#import torch_xla.core.xla_model as xm\n",
    "\n",
    "\n",
    "\n",
    "#import pennylane as qml\n",
    "#import pennylane.numpy as pnp\n",
    "\n",
    "import os, cv2, itertools # cv2 -- OpenCV\n",
    "import shutil\n",
    "import zipfile\n",
    "%matplotlib inline\n",
    "\n",
    "#from jax.lib import xla_bridge\n",
    "\n",
    "\n",
    "sns.set()\n",
    "\n",
    "seed = 1701\n",
    "rng = np.random.default_rng(seed=seed)\n",
    "#prng = pnp.random.default_rng(seed=seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "#torch.set_default_dtype(torch.double)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "COMPLEX_DTYPE = torch.cfloat #torch.cdouble\n",
    "REAL_DTYPE = torch.float\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WmQPQuLbSFw"
   },
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-03T08:26:54.097750Z",
     "iopub.status.busy": "2024-04-03T08:26:54.097431Z",
     "iopub.status.idle": "2024-04-03T08:26:54.405968Z",
     "shell.execute_reply": "2024-04-03T08:26:54.405273Z",
     "shell.execute_reply.started": "2024-04-03T08:26:54.097729Z"
    },
    "id": "rUhQUP2dbTja",
    "outputId": "0d3641db-a2ff-4689-8b7e-32e0e8b313d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32])\n",
      "tensor([7, 2, 7, 6, 4, 5, 7, 1, 8, 1, 1, 0, 8, 9, 7, 3, 1, 4, 6, 8, 2, 6, 5, 1,\n",
      "        5, 9, 7, 2, 6, 5, 5, 9])\n",
      "tensor([ 0.0275+0.j, -0.0196+0.j, -0.0353+0.j, -0.6078+0.j, -0.7961+0.j, -0.8118+0.j,\n",
      "        -0.8196+0.j, -0.7569+0.j, -0.7490+0.j, -0.7176+0.j, -0.7490+0.j, -0.7569+0.j,\n",
      "        -0.7647+0.j, -0.8118+0.j, -0.7569+0.j, -0.7412+0.j, -0.7804+0.j, -0.6157+0.j,\n",
      "         0.0118+0.j,  0.1294+0.j,  0.0902+0.j,  0.0902+0.j,  0.0196+0.j,  0.0196+0.j,\n",
      "         0.0745+0.j,  0.0745+0.j,  0.0667+0.j,  0.0824+0.j,  0.0431+0.j,  0.0039+0.j,\n",
      "        -0.0118+0.j,  0.0118+0.j])\n"
     ]
    }
   ],
   "source": [
    "preprocess = torchvision.transforms.Compose([\n",
    "    #torchvision.transforms.Pad(2),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    #torchvision.transforms.Lambda(lambda x: torch.squeeze(x)),\n",
    "    #torchvision.transforms.Lambda(lambda x: x / torch.trace(x)),\n",
    "    #torchvision.transforms.Lambda(lambda x: (x+torch.t(x))/2)\n",
    "    torchvision.transforms.Normalize((0.5,), (0.5,)),\n",
    "    torchvision.transforms.Lambda(lambda x: x.type(COMPLEX_DTYPE))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    \"CIFAR10\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=preprocess,\n",
    ")\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    \"CIFAR10\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=preprocess,\n",
    ")\n",
    "dummy_trainloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=32, shuffle=True\n",
    ")\n",
    "dummy_testloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=32, shuffle=True\n",
    ")\n",
    "\n",
    "dummy_x, dummy_y = next(iter(dummy_trainloader))\n",
    "\n",
    "print(dummy_x.shape)  # 64x32x32\n",
    "print(dummy_y.shape)  # 64\n",
    "print(dummy_y)\n",
    "print(dummy_x[0,0,16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQI8WWY6byQq"
   },
   "source": [
    "# Some Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-03T08:26:54.407720Z",
     "iopub.status.busy": "2024-04-03T08:26:54.407518Z",
     "iopub.status.idle": "2024-04-03T08:26:56.071027Z",
     "shell.execute_reply": "2024-04-03T08:26:56.069162Z",
     "shell.execute_reply.started": "2024-04-03T08:26:54.407700Z"
    },
    "id": "7B4DTncWbwQl",
    "outputId": "38975b7c-66c4-49f5-e5fd-158e55028cdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n",
      "        [1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
      "        [0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n",
      "        [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j]], device='cuda:0'), tensor([[0.+0.j, 0.-1.j, 0.+0.j, 0.-0.j],\n",
      "        [0.+1.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
      "        [0.+0.j, 0.-0.j, 0.+0.j, 0.-1.j],\n",
      "        [0.+0.j, 0.+0.j, 0.+1.j, 0.+0.j]], device='cuda:0'), tensor([[ 1.+0.j,  0.+0.j,  0.+0.j,  0.+0.j],\n",
      "        [ 0.+0.j, -1.+0.j,  0.+0.j, -0.+0.j],\n",
      "        [ 0.+0.j,  0.+0.j,  1.+0.j,  0.+0.j],\n",
      "        [ 0.+0.j, -0.+0.j,  0.+0.j, -1.+0.j]], device='cuda:0'), tensor([[0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\n",
      "        [0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n",
      "        [1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
      "        [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j]], device='cuda:0'), tensor([[0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n",
      "        [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\n",
      "        [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n",
      "        [1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]], device='cuda:0'), tensor([[0.+0.j, 0.-0.j, 0.+0.j, 0.-1.j],\n",
      "        [0.+0.j, 0.+0.j, 0.+1.j, 0.+0.j],\n",
      "        [0.+0.j, 0.-1.j, 0.+0.j, 0.-0.j],\n",
      "        [0.+1.j, 0.+0.j, 0.+0.j, 0.+0.j]], device='cuda:0'), tensor([[ 0.+0.j,  0.+0.j,  1.+0.j,  0.+0.j],\n",
      "        [ 0.+0.j, -0.+0.j,  0.+0.j, -1.+0.j],\n",
      "        [ 1.+0.j,  0.+0.j,  0.+0.j,  0.+0.j],\n",
      "        [ 0.+0.j, -1.+0.j,  0.+0.j, -0.+0.j]], device='cuda:0'), tensor([[0.+0.j, 0.+0.j, 0.-1.j, 0.-0.j],\n",
      "        [0.+0.j, 0.+0.j, 0.-0.j, 0.-1.j],\n",
      "        [0.+1.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
      "        [0.+0.j, 0.+1.j, 0.+0.j, 0.+0.j]], device='cuda:0'), tensor([[0.+0.j, 0.+0.j, 0.-0.j, 0.-1.j],\n",
      "        [0.+0.j, 0.+0.j, 0.-1.j, 0.-0.j],\n",
      "        [0.+0.j, 0.+1.j, 0.+0.j, 0.+0.j],\n",
      "        [0.+1.j, 0.+0.j, 0.+0.j, 0.+0.j]], device='cuda:0'), tensor([[ 0.+0.j,  0.-0.j,  0.-0.j, -1.+0.j],\n",
      "        [ 0.+0.j,  0.+0.j,  1.-0.j,  0.-0.j],\n",
      "        [ 0.+0.j,  1.-0.j,  0.+0.j,  0.-0.j],\n",
      "        [-1.+0.j,  0.+0.j,  0.+0.j,  0.+0.j]], device='cuda:0'), tensor([[0.+0.j, 0.+0.j, 0.-1.j, 0.-0.j],\n",
      "        [0.+0.j, -0.+0.j, 0.-0.j, 0.+1.j],\n",
      "        [0.+1.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
      "        [0.+0.j, -0.-1.j, 0.+0.j, -0.+0.j]], device='cuda:0'), tensor([[ 1.+0.j,  0.+0.j,  0.+0.j,  0.+0.j],\n",
      "        [ 0.+0.j,  1.+0.j,  0.+0.j,  0.+0.j],\n",
      "        [ 0.+0.j,  0.+0.j, -1.+0.j, -0.+0.j],\n",
      "        [ 0.+0.j,  0.+0.j, -0.+0.j, -1.+0.j]], device='cuda:0'), tensor([[ 0.+0.j,  1.+0.j,  0.+0.j,  0.+0.j],\n",
      "        [ 1.+0.j,  0.+0.j,  0.+0.j,  0.+0.j],\n",
      "        [ 0.+0.j,  0.+0.j, -0.+0.j, -1.+0.j],\n",
      "        [ 0.+0.j,  0.+0.j, -1.+0.j, -0.+0.j]], device='cuda:0'), tensor([[0.+0.j, 0.-1.j, 0.+0.j, 0.-0.j],\n",
      "        [0.+1.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
      "        [0.+0.j, 0.-0.j, -0.+0.j, 0.+1.j],\n",
      "        [0.+0.j, 0.+0.j, -0.-1.j, -0.+0.j]], device='cuda:0'), tensor([[ 1.+0.j,  0.+0.j,  0.+0.j,  0.+0.j],\n",
      "        [ 0.+0.j, -1.+0.j,  0.+0.j, -0.+0.j],\n",
      "        [ 0.+0.j,  0.+0.j, -1.+0.j, -0.+0.j],\n",
      "        [ 0.+0.j, -0.+0.j, -0.+0.j,  1.-0.j]], device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "ket = {\n",
    "    '0':torch.tensor([1.,0.], dtype = COMPLEX_DTYPE, device=device),\n",
    "    '1':torch.tensor([0.,1.], dtype = COMPLEX_DTYPE, device=device),\n",
    "    '+':(torch.tensor([1,0], dtype = COMPLEX_DTYPE, device=device) + torch.tensor([0,1], dtype = COMPLEX_DTYPE, device=device))/torch.sqrt(torch.tensor(2, dtype = COMPLEX_DTYPE, device=device)),\n",
    "    '-':(torch.tensor([1,0], dtype = COMPLEX_DTYPE, device=device) - torch.tensor([0,1], dtype = COMPLEX_DTYPE, device=device))/torch.sqrt(torch.tensor(2, dtype = COMPLEX_DTYPE, device=device))\n",
    "}\n",
    "\n",
    "pauli = {\n",
    "    'I':torch.tensor([[1.,0.],[0.,1.]], dtype = COMPLEX_DTYPE, device=device),\n",
    "    'X':torch.tensor([[0.,1.],[1.,0.]], dtype = COMPLEX_DTYPE, device=device),\n",
    "    'Y':torch.tensor([[0., -1.j],[1.j, 0]], dtype = COMPLEX_DTYPE, device=device),\n",
    "    'Z':torch.tensor([[1.,0.],[0.,-1.]], dtype = COMPLEX_DTYPE, device=device)\n",
    "}\n",
    "\n",
    "def tensor_product(*args):\n",
    "  input_list = [a for a in args]\n",
    "  return functools.reduce(torch.kron, input_list)\n",
    "\n",
    "def multi_qubit_identity(n_qubits:int):\n",
    "  assert n_qubits>0\n",
    "  if n_qubits == 1:\n",
    "    return pauli['I']\n",
    "  else:\n",
    "    return tensor_product(*[pauli['I'] for _ in range(n_qubits)])\n",
    "\n",
    "pauli_words_su4 = {}\n",
    "for key1 in pauli.keys():\n",
    "  for key2 in pauli.keys():\n",
    "    if not (key1==key2 and key1=='I' and key2=='I'):\n",
    "      #print(key1, key2)\n",
    "      #print(pauli[key1])\n",
    "      #print(pauli[key2])\n",
    "      pauli_words_su4[key1+key2] = tensor_product(pauli[key1], pauli[key2])\n",
    "      #print(pauli_words_su4[key1+key2])\n",
    "\n",
    "pauli_words_su8 = {}\n",
    "for key1 in pauli.keys():\n",
    "  for key2 in pauli.keys():\n",
    "    for key3 in pauli.keys():\n",
    "      if not key1+key2+key3 == 'III':\n",
    "        pauli_words_su8[key1+key2+key3] = tensor_product(pauli[key1], pauli[key2], pauli[key3])\n",
    "\n",
    "pauli_words_su16 = {}\n",
    "for key1 in pauli.keys():\n",
    "  for key2 in pauli.keys():\n",
    "    for key3 in pauli.keys():\n",
    "      for key4 in pauli.keys():\n",
    "        if not key1+key2+key3+key4 == 'IIII':\n",
    "          pauli_words_su16[key1+key2+key3+key4] = tensor_product(\n",
    "              pauli[key1],\n",
    "              pauli[key2],\n",
    "              pauli[key3],\n",
    "              pauli[key4]\n",
    "          )\n",
    "\n",
    "pauli_words_su32 = {}\n",
    "for key1 in pauli.keys():\n",
    "  for key2 in pauli.keys():\n",
    "    for key3 in pauli.keys():\n",
    "      for key4 in pauli.keys():\n",
    "        for key5 in pauli.keys():\n",
    "          if not key1+key2+key3+key4+key5 == 'IIIII':\n",
    "            pauli_words_su32[key1+key2+key3+key4+key5] = tensor_product(\n",
    "                pauli[key1],\n",
    "                pauli[key2],\n",
    "                pauli[key3],\n",
    "                pauli[key4],\n",
    "                pauli[key5]\n",
    "            )\n",
    "\n",
    "def su32_op(\n",
    "    params\n",
    "):\n",
    "  dict_values = list(pauli_words_su32.values())\n",
    "  generator = torch.einsum(\"i,ijk->jk\", params, torch.stack(dict_values))\n",
    "  #print(generator.shape)\n",
    "  return torch.matrix_exp(1j*generator)\n",
    "\n",
    "def su4_op(\n",
    "    params\n",
    "):\n",
    "  dict_values = torch.stack(list(pauli_words_su4.values()))\n",
    "  #print(dict_values.shape)\n",
    "  generator = torch.einsum(\"i, ijk -> jk\", params, dict_values)\n",
    "  return torch.linalg.matrix_exp(1.0j*generator)\n",
    "\n",
    "def pauli_dict_func(key):\n",
    "    return pauli[key]\n",
    "\n",
    "def pauli_dict_func_multiple_keys(keys):\n",
    "    return list(map(pauli_dict_func, keys))\n",
    "\n",
    "def pauli_string_tensor_prod(pauli_string:str):\n",
    "    paulis_char = list(pauli_string)\n",
    "    paulis_mat = pauli_dict_func_multiple_keys(paulis_char)\n",
    "    return tensor_product(*paulis_mat)\n",
    "\n",
    "def generate_nqubit_pauli_strings(n_qubits:int):\n",
    "    assert n_qubits>0\n",
    "    pauli_labels = ['I', 'X', 'Y', 'Z']\n",
    "    pauli_strings = []\n",
    "    for labels in itertools.product(pauli_labels, repeat=n_qubits):\n",
    "        pauli_str = \"\".join(labels)\n",
    "        if pauli_str != 'I'*n_qubits:\n",
    "            pauli_strings.append(pauli_str)\n",
    "    return pauli_strings\n",
    "\n",
    "def generate_pauli_tensor_list(pauli_strings:list):\n",
    "    return list(map(pauli_string_tensor_prod, pauli_strings))\n",
    "\n",
    "\n",
    "print(\n",
    "    generate_pauli_tensor_list(generate_nqubit_pauli_strings(2))\n",
    ")\n",
    "\n",
    "\n",
    "#test_params = torch.randn(4**2-1,  device=device).type(COMPLEX_DTYPE)\n",
    "#print(test_params.shape)\n",
    "#test_op = su4_op(test_params)\n",
    "#print(test_op)\n",
    "#print(qml.is_unitary(qml.QubitUnitary(test_op.cpu().numpy(), wires=[0,1]))) # will be false if not torch.cdouble\n",
    "\n",
    "#rx = torch.linalg.matrix_exp(1j*torch.pi*pauli[\"X\"]/2)\n",
    "#print(qml.is_unitary(qml.QubitUnitary(rx.cpu().numpy(), wires=[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T08:26:56.073077Z",
     "iopub.status.busy": "2024-04-03T08:26:56.072615Z",
     "iopub.status.idle": "2024-04-03T08:26:56.079092Z",
     "shell.execute_reply": "2024-04-03T08:26:56.078390Z",
     "shell.execute_reply.started": "2024-04-03T08:26:56.073053Z"
    },
    "id": "Xs0c2F1eBnGc"
   },
   "outputs": [],
   "source": [
    "def measure_sv(\n",
    "    state,\n",
    "    observable\n",
    "    ):\n",
    "  \"\"\"\n",
    "  Measure a statevector with a Hermitian observable.\n",
    "  Note: No checking Hermitianicity of the observable or whether the observable\n",
    "  has all real eigenvalues or not\n",
    "  \"\"\"\n",
    "  expectation_value = torch.conj(state)@observable@state\n",
    "  return torch.real(expectation_value)\n",
    "\n",
    "def measure_dm(\n",
    "    rho,\n",
    "    observable\n",
    "):\n",
    "  \"\"\"\n",
    "  Measure a density matrix with a Hermitian observable.\n",
    "  Note: No checking Hermitianicity of the observable or whether the observable\n",
    "  has all real eigenvalues or not.\n",
    "  \"\"\"\n",
    "  product = torch.matmul(rho, observable)\n",
    "\n",
    "  # Calculate the trace, which is the sum of diagonal elements\n",
    "  trace = torch.trace(product)\n",
    "\n",
    "  # The expectation value should be real for physical observables\n",
    "  return torch.real(trace)\n",
    "\n",
    "vmap_measure_sv = torch.vmap(measure_sv, in_dims=(None, 0), out_dims=0)\n",
    "vmap_measure_dm = torch.vmap(measure_dm, in_dims=(None, 0), out_dims=0)\n",
    "\n",
    "# assuming the input patch observables (hermitianized) has shape (batchsize,n_patches, c, h, w)\n",
    "# assuming the input set statevectors has shape (c, 2**n)\n",
    "# output should have the shape (batchsize,n_patches, channel)\n",
    "vmap_measure_channel_sv_batched_ob = torch.vmap(measure_sv, in_dims = (-2, -3),out_dims=-1)\n",
    "\n",
    "\n",
    "# assuming the input set desnity matrices has shape (batchsize, n_patches, c, 2**n, 2**n)\n",
    "# output should have the shape (batchsize,n_patches, channel)\n",
    "vmap_measure_channel_dm_batched_ob = torch.vmap(measure_dm, in_dims = (-2, -3),out_dims=-1)\n",
    "\n",
    "\n",
    "def bitstring_to_state(bitstring:str):\n",
    "  \"\"\"\n",
    "  Convert a bit string, like '0101001' or '+-+-101'\n",
    "  to a statevector. Each character in the bitstring must be among\n",
    "  0, 1, + and -\n",
    "  \"\"\"\n",
    "  assert len(bitstring)>0\n",
    "  for c in bitstring:\n",
    "    assert c in ['0', '1', '+', '-']\n",
    "  single_qubit_states = [ket[c] for c in bitstring]\n",
    "  return tensor_product(*single_qubit_states)\n",
    "\n",
    "\n",
    "#test_patch = torch.randn(size=[5, 2, 3, 4,4], dtype = torch.double, device=device).type(torch.cdouble)\n",
    "#test_herm_patch = (torch.einsum(\"...jk->...kj\", test_patch)+test_patch)/2\n",
    "#print(test_herm_patch)\n",
    "#print(\"all patches shape\", test_herm_patch.shape)\n",
    "#test_sv = torch.stack([bitstring_to_state('++')]*3, axis = 0)\n",
    "#print(test_sv)\n",
    "#print(\"all sv shape\", test_sv.shape)\n",
    "#res = vmap_measure_channel_sv_batched_ob(test_sv, test_herm_patch)\n",
    "#print(res)\n",
    "#print(\"res shape\",res.shape)\n",
    "\n",
    "#for batchid in range(test_patch.shape[0]):\n",
    "#  batchitem = test_patch[batchid]\n",
    "#  for patch_idx in range(batchitem.shape[0]):\n",
    "#    patch = batchitem[patch_idx]\n",
    "#    for ch_idx in range(patch.shape[0]):\n",
    "#      print(f\"batchid={batchid}; patchid = {patch_idx}; chid = {ch_idx}\")\n",
    "#      ch = patch[ch_idx]\n",
    "#      #print(ch.shape)\n",
    "#      sv_ch = test_sv[ch_idx]\n",
    "#      #print(sv_ch.shape)\n",
    "#      print(measure_sv(sv_ch, ch))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFZqT6bpElaL"
   },
   "source": [
    "# Flipped Quanvolution Kernel\n",
    "\n",
    "First, let's define the function to extract patches for a single kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T08:26:56.080443Z",
     "iopub.status.busy": "2024-04-03T08:26:56.079871Z",
     "iopub.status.idle": "2024-04-03T08:26:56.085801Z",
     "shell.execute_reply": "2024-04-03T08:26:56.085133Z",
     "shell.execute_reply.started": "2024-04-03T08:26:56.080420Z"
    },
    "id": "He4HdMRHC7T6"
   },
   "outputs": [],
   "source": [
    "def extract_patches(image, patch_size, stride, padding=None):\n",
    "    \"\"\"\n",
    "    Extracts patches from an image with multiple input channels and optional custom padding.\n",
    "\n",
    "    Args:\n",
    "        image (torch.Tensor): Input image tensor of shape (in_channels, height, width).\n",
    "        patch_size (int): Size of the square patches to extract.\n",
    "        stride (int): Stride between patches.\n",
    "        padding (tuple): Padding value(s) for each dimension.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Tensor of extracted patches of shape (num_patches, in_channels, patch_size, patch_size).\n",
    "    \"\"\"\n",
    "    in_channels, height, width = image.shape[-3], image.shape[-2], image.shape[-1]\n",
    "    pad_l, pad_r, pad_t, pad_b = padding if padding is not None else (0,0,0,0)\n",
    "\n",
    "    if padding is not None:\n",
    "        image = torch.nn.functional.pad(image, (pad_l, pad_r, pad_t, pad_b), mode='constant')\n",
    "    else:\n",
    "        image = image\n",
    "\n",
    "    height, width = image.shape[-2],  image.shape[-1]\n",
    "    num_patches_h = (height - patch_size) // stride + 1\n",
    "    num_patches_w = (width - patch_size) // stride + 1\n",
    "\n",
    "    patches = []\n",
    "    for i in range(num_patches_h):\n",
    "        for j in range(num_patches_w):\n",
    "            patch = image[..., i*stride:i*stride+patch_size, j*stride:j*stride+patch_size]\n",
    "            patches.append(patch)\n",
    "\n",
    "    patches = torch.stack(patches, dim=-4)\n",
    "    return patches # has shape (batchsize, n_patches, channel, h, w)\n",
    "\n",
    "\n",
    "#single_img = torch.stack([torch.arange(32*32*1,dtype = torch.double, device=device).reshape((32,32)).type(torch.cdouble)]*3)\n",
    "\n",
    "#test_img = torch.stack([single_img]*2)\n",
    "#print(test_img[0][...,:4,:4])\n",
    "#patches = extract_patches(test_img, patch_size=4, stride=2,padding=(0,0,0,0))\n",
    "#print(patches.shape)\n",
    "#print(patches[0].shape)\n",
    "#print(patches[0][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hRqflooEqKN"
   },
   "source": [
    "## A Three-by-Three Quanv Kernel Function\n",
    "\n",
    "For 3 by 3 patches, we only need a 2-qubit parameterised state, generated by the SU4 gate applied to the $|00\\rangle$ state. The first thing to do is to pad the 3 by 3 patches to 4 by 4. However, for input with size\n",
    "\n",
    "$$\n",
    "D_1\\times H_1 \\times W_1\n",
    "$$\n",
    "\n",
    "where $D_1$ is the number of input channels, we will need $D_1$ different two-qubit states, generated by $D_1$ different parameterised circuits. These circuits will produce $D_1$ expectation values. Suppose each circuit is parameterised by $\\theta_i, i\\in \\{1,2,\\cdots, D_1\\}$, the parameterised (pure) state can be written as\n",
    "\n",
    "$$\n",
    "|\\psi (\\theta_i)⟩ = SU4(\\theta_i)|00⟩\n",
    "$$\n",
    "\n",
    "For a channel $M_i$ of patch $M$ with shape $4\\times 4$, the expectation value is calculated by\n",
    "\n",
    "$$\n",
    "⟨\\psi(\\theta_i)|\\left(\\frac{M_i+M^T_i}{2}\\right)|\\psi(\\theta_i)⟩\n",
    "$$\n",
    "\n",
    "Then, a single pixel value of the output channel corresponding this single kernel is\n",
    "\n",
    "$$\n",
    "\\frac{1}{D_1}\\sum_{i=1}^{D_1}⟨\\psi(\\theta_i)|\\left(\\frac{M_i+M^T_i}{2}\\right)|\\psi(\\theta_i)⟩\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T08:26:56.086697Z",
     "iopub.status.busy": "2024-04-03T08:26:56.086517Z",
     "iopub.status.idle": "2024-04-03T08:26:56.091796Z",
     "shell.execute_reply": "2024-04-03T08:26:56.091178Z",
     "shell.execute_reply.started": "2024-04-03T08:26:56.086679Z"
    },
    "id": "Yzn4KEt5ErG7"
   },
   "outputs": [],
   "source": [
    "def generate_2q_param_state(theta):\n",
    "  state = bitstring_to_state('00')\n",
    "  state = torch.matmul(su4_op(theta), state)\n",
    "  return state\n",
    "\n",
    "vmap_generate_2q_param_state = torch.vmap(generate_2q_param_state, in_dims=0, out_dims = 0)\n",
    "\n",
    "def single_kernel_op_over_batched_patches(thetas, patch):\n",
    "  # patch has shape (c_in, h, w)\n",
    "  # thetas has shape (c_in, 4^2-1) for SU4 gates\n",
    "  n_theta = thetas.shape[-2]\n",
    "  n_channel = patch.shape[-3]\n",
    "  assert n_theta == n_channel, \"Thetas and patch must have the same number of channels.\"\n",
    "  states = vmap_generate_2q_param_state(thetas)\n",
    "  #print(\"States shape\", states.shape)\n",
    "  patch = torch.nn.functional.pad(patch, (0, 1, 0, 1), mode='constant')\n",
    "  patch_t = torch.einsum(\"...jk->...kj\", patch)\n",
    "  herm_patch = (patch_t+patch)/2 # has dim (batchsize, num_patches, c, h, w)\n",
    "  #print(\"Herm patch shape\", herm_patch.shape)\n",
    "  channel_out = vmap_measure_channel_sv_batched_ob(states, herm_patch) # has dim (batchsize,n_patches, c)\n",
    "  return torch.sum(channel_out, axis = -1)/n_theta # has dim (batchszie, n_patches)\n",
    "\n",
    "\n",
    "#test_params = torch.randn((1,4**2-1), dtype = torch.double, device=device).type(torch.cdouble)\n",
    "#test_img = dummy_x.to(device)#.type(torch.cdouble)\n",
    "#print(test_img.shape)\n",
    "#test_patches = extract_patches(test_img, patch_size=3, stride=1,padding=(1,1,1,1))\n",
    "#print(test_patches.shape)\n",
    "#print(test_params.shape)\n",
    "#print(vmap_generate_2q_param_state(test_params))\n",
    "#test_out = single_kernel_op_over_batched_patches(test_params, test_patches)\n",
    "#print(test_out.shape)\n",
    "#h = (32-3+1*2)//1 +1\n",
    "#h**2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4BXEKd8I67_"
   },
   "source": [
    "## Multiple Output Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T08:26:56.092668Z",
     "iopub.status.busy": "2024-04-03T08:26:56.092483Z",
     "iopub.status.idle": "2024-04-03T08:26:56.095952Z",
     "shell.execute_reply": "2024-04-03T08:26:56.095319Z",
     "shell.execute_reply.started": "2024-04-03T08:26:56.092650Z"
    },
    "id": "72vkHV_BI80l"
   },
   "outputs": [],
   "source": [
    "# For multiple channel output\n",
    "# parameter has shape (c_out, c_in, 4**2-1) for SU4 gates\n",
    "vmap_vmap_single_kernel_op_through_extracted_patches = torch.vmap(single_kernel_op_over_batched_patches, in_dims=(0, None), out_dims=-2) # output has dim (batchsize, c_out, n_patches)\n",
    "\n",
    "#c_in = 1\n",
    "#c_out = 2\n",
    "\n",
    "#test_params2 = torch.randn((c_out, c_in,4**2-1), dtype = torch.double, device=device).type(torch.cdouble)\n",
    "#test_out2 = vmap_vmap_single_kernel_op_through_extracted_patches(test_params2, test_patches)\n",
    "#print(test_out2.shape)\n",
    "#test_out_2_features = test_out2.reshape((-1,c_out, 32, 32))\n",
    "#print(test_out_2_features.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuZ6G5-sKK_J"
   },
   "source": [
    "## Pytorch Module for Three-by-Three Flipped Quanv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T08:26:56.096785Z",
     "iopub.status.busy": "2024-04-03T08:26:56.096604Z",
     "iopub.status.idle": "2024-04-03T08:26:56.103091Z",
     "shell.execute_reply": "2024-04-03T08:26:56.102542Z",
     "shell.execute_reply.started": "2024-04-03T08:26:56.096768Z"
    },
    "id": "Gww_XdJ5KPJt"
   },
   "outputs": [],
   "source": [
    "class FlippedQuanv3x3(torch.nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, stride, padding):\n",
    "    super(FlippedQuanv3x3, self).__init__()\n",
    "    self.in_channels = in_channels\n",
    "    self.out_channels = out_channels\n",
    "    self.stride = stride\n",
    "    self.padding = padding\n",
    "    self.pad_l, self.pad_r, self.pad_t, self.pad_b = padding if padding is not None else (0,0,0,0)\n",
    "    self.pad = (self.pad_l, self.pad_r, self.pad_t, self.pad_b)\n",
    "    self.weight= torch.nn.Parameter(torch.randn((out_channels, in_channels, 4**2-1)).type(COMPLEX_DTYPE))\n",
    "    self.bias = torch.nn.Parameter(torch.randn((out_channels, 1)).type(COMPLEX_DTYPE))\n",
    "\n",
    "  def forward(self, x):\n",
    "    # x has shape (batchsize ,c_in, h, w)\n",
    "    # weight has shape (c_out, c_in, 15)\n",
    "    # bias has shape (c_out, 1)\n",
    "    x = x.type(COMPLEX_DTYPE)\n",
    "    c_in, h_in, w_in = x.shape[-3], x.shape[-2], x.shape[-1]\n",
    "    patches = extract_patches(x, patch_size=3, stride=self.stride, padding=self.pad)\n",
    "    h_out = (h_in-3+(self.pad_t+self.pad_b))//self.stride +1\n",
    "    w_out = (w_in-3+(self.pad_l+self.pad_r))//self.stride +1\n",
    "\n",
    "    #print(self.weight.shape)\n",
    "    #print(patches.shape)\n",
    "\n",
    "    out = vmap_vmap_single_kernel_op_through_extracted_patches(self.weight, patches)\n",
    "\n",
    "\n",
    "    out = out + self.bias\n",
    "    return out.reshape((-1,self.out_channels, h_out, w_out)).type(REAL_DTYPE)\n",
    "\n",
    "  def extra_repr(self) -> str:\n",
    "        return f'in_channels={self.in_channels}, out_channels={self.out_channels}, stride={self.stride}, padding={self.padding}'\n",
    "\n",
    "#test_module = FlippedQuanv3x3(in_channels=1, out_channels=2, stride=1, padding=(1,1,1,1)).to(device)\n",
    "#print(dummy_x.shape)\n",
    "#test_out = test_module(dummy_x.to(device))\n",
    "#print(test_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5jY9sQZ7Ynla"
   },
   "source": [
    "# Linear Layer\n",
    "\n",
    "For input dimension $D$, the quantum linear layer is a $n = \\lceil \\log_4(D+1)⌉$-qubit quantum circuit. Both the data encoding and parameterised circuit is achieved via the $SU(2^n)$ unitary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T08:26:56.103883Z",
     "iopub.status.busy": "2024-04-03T08:26:56.103708Z",
     "iopub.status.idle": "2024-04-03T08:26:57.562457Z",
     "shell.execute_reply": "2024-04-03T08:26:57.561682Z",
     "shell.execute_reply.started": "2024-04-03T08:26:56.103865Z"
    },
    "id": "AXxNIObFYnPW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0847, 0.6649, 0.0675, 0.1829], device='cuda:0')\n",
      "tensor(1.0000, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def data_encode_unitary(padded_data, t):\n",
    "  original_dim = padded_data.shape[-1]\n",
    "  new_dim = torch.sqrt(torch.tensor(original_dim)).type(torch.int)\n",
    "  data = torch.reshape(padded_data, (new_dim, new_dim))\n",
    "  generator = (data + torch.einsum(\"...jk->...kj\", data))/2\n",
    "  return torch.linalg.matrix_exp(1.0j*generator*t)\n",
    "\n",
    "def su_n(params, pauli_string_tensor_list):\n",
    "  # params has dim 4**n-1\n",
    "  paulis = torch.stack(pauli_string_tensor_list)\n",
    "  generator = torch.einsum(\"i,ijk->jk\", params, paulis)\n",
    "  return torch.linalg.matrix_exp(1.0j*generator)\n",
    "\n",
    "def linear_layer_func(padded_data, params, pauli_string_tensor_list, observables, n_qubits):\n",
    "  n_rep = params.shape[0]\n",
    "  state = bitstring_to_state(\"+\"*n_qubits)\n",
    "  for i in range(n_rep):\n",
    "    data_unitary = data_encode_unitary(padded_data, 1/n_rep)\n",
    "    #print(data_unitary.shape)\n",
    "    #print(state.shape)\n",
    "    state = torch.matmul(\n",
    "      data_unitary,\n",
    "      state\n",
    "    )\n",
    "    sun_gate = su_n(params[i], pauli_string_tensor_list)\n",
    "    #print(sun_gate.shape)\n",
    "    state = torch.matmul(\n",
    "      sun_gate,\n",
    "      state\n",
    "    )\n",
    "  return vmap_measure_sv(state, observables)\n",
    "\n",
    "test_params = torch.randn((3, 4**2-1),device=device).type(COMPLEX_DTYPE)\n",
    "test_data = torch.randn(4**2, device=device).type(COMPLEX_DTYPE)\n",
    "test_obs = torch.stack([torch.outer(bitstring_to_state('00'), bitstring_to_state('00')),\n",
    "                        torch.outer(bitstring_to_state('01'), bitstring_to_state('01')),\n",
    "                        torch.outer(bitstring_to_state('10'), bitstring_to_state('10')),\n",
    "                         torch.outer(bitstring_to_state('11'), bitstring_to_state('11'))])\n",
    "test_pauli_string_tensor_list = generate_pauli_tensor_list(generate_nqubit_pauli_strings(2))\n",
    "\n",
    "\n",
    "test_out = linear_layer_func(test_data, test_params, test_pauli_string_tensor_list, test_obs, 2)\n",
    "print(test_out)\n",
    "print(torch.sum(test_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T08:26:57.564844Z",
     "iopub.status.busy": "2024-04-03T08:26:57.564417Z",
     "iopub.status.idle": "2024-04-03T08:26:57.576557Z",
     "shell.execute_reply": "2024-04-03T08:26:57.575906Z",
     "shell.execute_reply.started": "2024-04-03T08:26:57.564823Z"
    },
    "id": "2F4_SBgIYnMv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3414, 0.4328, 0.0295, 0.1964],\n",
      "        [0.4175, 0.1313, 0.2182, 0.2330],\n",
      "        [0.1889, 0.5187, 0.1613, 0.1311]], device='cuda:0')\n",
      "tensor(3.0000, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "vmap_batch_linear_layer_func = torch.vmap(linear_layer_func, in_dims=(0, None, None, None, None), out_dims=0)\n",
    "\n",
    "test_data = torch.randn((3, 4**2), device=device).type(COMPLEX_DTYPE)\n",
    "test_out = vmap_batch_linear_layer_func(test_data, test_params, test_pauli_string_tensor_list, test_obs, 2)\n",
    "print(test_out)\n",
    "print(torch.sum(test_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ryROGtnC_3po"
   },
   "source": [
    "## PyTorch Module for the Quantum Version of Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T08:26:57.577462Z",
     "iopub.status.busy": "2024-04-03T08:26:57.577280Z",
     "iopub.status.idle": "2024-04-03T08:26:57.605899Z",
     "shell.execute_reply": "2024-04-03T08:26:57.605187Z",
     "shell.execute_reply.started": "2024-04-03T08:26:57.577443Z"
    },
    "id": "RlTC952w_8VW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 45])\n",
      "torch.Size([16, 6])\n",
      "DataReUploadingLinear(in_dim=45, out_dim=6, n_qubits=3, n_reps=10)\n"
     ]
    }
   ],
   "source": [
    "class DataReUploadingLinear(torch.nn.Module):\n",
    "  def __init__(self, in_dim, out_dim, n_qubits, n_reps):\n",
    "    super(DataReUploadingLinear, self).__init__()\n",
    "    assert 2**n_qubits >= out_dim\n",
    "    assert 4**n_qubits >= in_dim\n",
    "    self.in_dim = in_dim\n",
    "    self.out_dim = out_dim\n",
    "    self.n_qubits = n_qubits\n",
    "    self.n_reps = n_reps\n",
    "    self.pauli_string_tensor_list = generate_pauli_tensor_list(generate_nqubit_pauli_strings(n_qubits))\n",
    "    self.param_dim = 4**n_qubits-1\n",
    "    self.params = torch.nn.Parameter(torch.randn((self.n_reps,self.param_dim)).type(COMPLEX_DTYPE))\n",
    "    self.bias = torch.nn.Parameter(torch.randn(out_dim).type(REAL_DTYPE))\n",
    "    self.observables = self.generate_observables()\n",
    "    self.pad_size = 4**n_qubits-self.in_dim\n",
    "\n",
    "  def forward(self, x):\n",
    "    # x has size (batchsize, in_dim)\n",
    "    # pad x\n",
    "    x = torch.nn.functional.pad(x, (0, self.pad_size)).type(COMPLEX_DTYPE)\n",
    "    out = vmap_batch_linear_layer_func(x, self.params, self.pauli_string_tensor_list, self.observables, self.n_qubits)\n",
    "    out = out.type(REAL_DTYPE) + self.bias\n",
    "    return out\n",
    "\n",
    "  def generate_observables(self):\n",
    "    observables = []\n",
    "    for i in range(self.out_dim):\n",
    "      temp_bitstring = '{0:b}'.format(i).zfill(self.n_qubits)\n",
    "      ob = torch.outer(bitstring_to_state(temp_bitstring), bitstring_to_state(temp_bitstring))\n",
    "      observables.append(ob)\n",
    "    return torch.stack(observables)\n",
    "\n",
    "  def extra_repr(self) -> str:\n",
    "        return f'in_dim={self.in_dim}, out_dim={self.out_dim}, n_qubits={self.n_qubits}, n_reps={self.n_reps}'\n",
    "\n",
    "test_linear_module = DataReUploadingLinear(in_dim=45, out_dim=6, n_qubits=3, n_reps = 10).to(device)\n",
    "test_data = torch.randn((16, 45), device=device).type(COMPLEX_DTYPE)\n",
    "print(test_data.shape)\n",
    "test_out = test_linear_module(test_data.to(device))\n",
    "print(test_out.shape)\n",
    "print(test_linear_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1yumZTjDVu63"
   },
   "source": [
    "# Replacing Classical Layers with Quantum Layers\n",
    "\n",
    "Let's replace `Conv2d` with `FlippedQuanv3x3`, and `Linear` with `QuantLinear`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-03T08:26:57.606924Z",
     "iopub.status.busy": "2024-04-03T08:26:57.606727Z",
     "iopub.status.idle": "2024-04-03T08:26:59.000203Z",
     "shell.execute_reply": "2024-04-03T08:26:58.999449Z",
     "shell.execute_reply.started": "2024-04-03T08:26:57.606905Z"
    },
    "id": "W4RC5ou-VzbE",
    "outputId": "9eb0b35d-ed18-431b-8a53-ba5216d3fd06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 32, 32])\n",
      "HybridNet(\n",
      "  (layers): Sequential(\n",
      "    (0): FlippedQuanv3x3(in_channels=3, out_channels=32, stride=1, padding=None)\n",
      "    (1): FlippedQuanv3x3(in_channels=32, out_channels=16, stride=1, padding=None)\n",
      "    (2): Flatten(start_dim=1, end_dim=-1)\n",
      "    (3): DataReUploadingLinear(in_dim=12544, out_dim=10, n_qubits=7, n_reps=10)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_509/4168075707.py:85: UserWarning: There is a performance drop because we have not yet implemented the batching rule for aten::matrix_exp. Please file us an issue on GitHub so that we can prioritize its implementation. (Triggered internally at ../aten/src/ATen/functorch/BatchedFallback.cpp:82.)\n",
      "  return torch.linalg.matrix_exp(1.0j*generator)\n",
      "/tmp/ipykernel_509/1684779817.py:30: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at ../aten/src/ATen/native/Copy.cpp:301.)\n",
      "  return out.reshape((-1,self.out_channels, h_out, w_out)).type(REAL_DTYPE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "class HybridNet(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(HybridNet, self).__init__()\n",
    "\n",
    "    self.layers = torch.nn.Sequential(\n",
    "        FlippedQuanv3x3(in_channels=3, out_channels=32, stride=1, padding=None), # 32->30\n",
    "        #torch.nn.ReLU(),\n",
    "        #torch.nn.MaxPool2d(kernel_size=2, stride=1),\n",
    "        FlippedQuanv3x3(in_channels=32, out_channels=16, stride=1, padding=None), # 30->28\n",
    "        #torch.nn.ReLU(),\n",
    "        #torch.nn.MaxPool2d(kernel_size=2, stride=1),\n",
    "        torch.nn.Flatten(),\n",
    "        DataReUploadingLinear(16*28*28, 10, 7, 10)\n",
    "        #torch.nn.Linear(32*14*14, 10).type(REAL_DTYPE)\n",
    "    )\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    logits = self.layers(x)\n",
    "    return logits\n",
    "\n",
    "\n",
    "net = HybridNet().to(device)\n",
    "test_img = dummy_x.to(device)\n",
    "print(test_img.shape)\n",
    "print(net)\n",
    "test_out = net(test_img)\n",
    "print(test_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "execution": {
     "iopub.execute_input": "2024-04-03T08:26:59.001280Z",
     "iopub.status.busy": "2024-04-03T08:26:59.001080Z",
     "iopub.status.idle": "2024-04-03T17:06:02.379965Z",
     "shell.execute_reply": "2024-04-03T17:06:02.379200Z",
     "shell.execute_reply.started": "2024-04-03T08:26:59.001260Z"
    },
    "id": "x4ZY59q1WS4x",
    "outputId": "6532aea1-47a3-49f3-fe36-b774aee1905f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train batches = 250, Number of test batches = 50\n",
      "Print every train batch = 25, Print every test batch = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_509/4168075707.py:85: UserWarning: There is a performance drop because we have not yet implemented the batching rule for aten::matrix_exp. Please file us an issue on GitHub so that we can prioritize its implementation. (Triggered internally at ../aten/src/ATen/functorch/BatchedFallback.cpp:82.)\n",
      "  return torch.linalg.matrix_exp(1.0j*generator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at step=0, batch=0, train loss = 2.482003688812256, train acc = 0.11500000208616257, time = 1.5793821811676025\n",
      "Training at step=0, batch=25, train loss = 2.5056371688842773, train acc = 0.09000000357627869, time = 0.9443156719207764\n"
     ]
    }
   ],
   "source": [
    "import torchmetrics\n",
    "#criterion = torch.nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "#accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
    "\n",
    "BATCH_SIZE = 200\n",
    "LEARNING_RATE = 3e-4\n",
    "STEPS = 100\n",
    "PRINT_EVERY_PERCENT = 0.1\n",
    "\n",
    "def train(\n",
    "    model,\n",
    "    optim=torch.optim.SGD,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    accuracy = torchmetrics.Accuracy,\n",
    "    steps = 100,\n",
    "    print_every_percent=0.1,\n",
    "    batchsize = 100,\n",
    "    lr = 0.001,\n",
    "    device=torch.device(\"cpu\")\n",
    "):\n",
    "  trainloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batchsize, shuffle=True\n",
    "  )\n",
    "  testloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batchsize, shuffle=True\n",
    "  )\n",
    "\n",
    "  n_train_batches = len(trainloader)\n",
    "  n_test_batches = len(testloader)\n",
    "  print_every_train_batch = int(n_train_batches*print_every_percent)\n",
    "  print_every_test_batch = int(n_test_batches*print_every_percent)\n",
    "\n",
    "  print(f\"Number of train batches = {n_train_batches}, Number of test batches = {n_test_batches}\")\n",
    "  print(f\"Print every train batch = {print_every_train_batch}, Print every test batch = {print_every_test_batch}\")\n",
    "\n",
    "  model.to(device)\n",
    "  optimizer = optim(model.parameters(), lr=lr, momentum=0.9)\n",
    "  loss = criterion()\n",
    "  acc_func = accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "  step_train_losses = []\n",
    "  step_test_losses = []\n",
    "  step_train_accs = []\n",
    "  step_test_accs = []\n",
    "  for i in range(steps):\n",
    "    step_start = time.time()\n",
    "    batch_train_loss = []\n",
    "    batch_train_acc = []\n",
    "    batch_test_loss = []\n",
    "    batch_test_acc = []\n",
    "    # train\n",
    "    model.train()\n",
    "    for batchid, (images, labels) in enumerate(trainloader):\n",
    "      batch_start = time.time()\n",
    "      images, labels = images.to(device), labels.to(device)\n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(images)\n",
    "      train_loss = loss(outputs, labels)\n",
    "      train_loss.backward()\n",
    "      optimizer.step()\n",
    "      train_acc = acc_func(outputs, labels)\n",
    "      batch_train_loss.append(train_loss.item())\n",
    "      batch_train_acc.append(train_acc.item())\n",
    "      batch_finish = time.time()\n",
    "\n",
    "      if (batchid) % print_every_train_batch == 0:\n",
    "        print(f\"Training at step={i}, batch={batchid}, train loss = {train_loss.item()}, train acc = {train_acc.item()}, time = {batch_finish-batch_start}\")\n",
    "\n",
    "    # eval\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      for batchid, (images, labels) in enumerate(testloader):\n",
    "        batch_start = time.time()\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        test_loss = loss(outputs, labels)\n",
    "        test_acc = acc_func(outputs, labels)\n",
    "        batch_test_loss.append(test_loss.item())\n",
    "        batch_test_acc.append(test_acc.item())\n",
    "        batch_finish = time.time()\n",
    "        if (batchid) % print_every_test_batch == 0:\n",
    "          print(f\"Testing at step={i}, batch={batchid}, test loss = {test_loss.item()}, test acc = {test_acc.item()}, time = {batch_finish-batch_start}\")\n",
    "\n",
    "    step_train_losses.append(np.mean(batch_train_loss))\n",
    "    step_test_losses.append(np.mean(batch_test_loss))\n",
    "    step_train_accs.append(np.mean(batch_train_acc))\n",
    "    step_test_accs.append(np.mean(batch_test_acc))\n",
    "    step_finish = time.time()\n",
    "    print(f\"Step {i} finished in {step_finish-step_start}, Train loss = {step_train_losses[-1]}, Test loss = {step_test_losses[-1]}; Train Acc = {step_train_accs[-1]}, Test Acc = {step_test_accs[-1]}\")\n",
    "\n",
    "  return step_train_losses, step_test_losses, step_train_accs, step_test_accs\n",
    "\n",
    "train_losses, test_losses, train_accs, test_accs = train(net,\n",
    "                                                        optim=torch.optim.SGD,\n",
    "                                                        criterion=torch.nn.CrossEntropyLoss,\n",
    "                                                        accuracy = torchmetrics.Accuracy,\n",
    "                                                        steps = STEPS,\n",
    "                                                        print_every_percent=PRINT_EVERY_PERCENT,\n",
    "                                                        batchsize = BATCH_SIZE,\n",
    "                                                        lr = LEARNING_RATE,\n",
    "                                                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T17:06:02.381493Z",
     "iopub.status.busy": "2024-04-03T17:06:02.381278Z",
     "iopub.status.idle": "2024-04-03T17:06:02.758413Z",
     "shell.execute_reply": "2024-04-03T17:06:02.757799Z",
     "shell.execute_reply.started": "2024-04-03T17:06:02.381473Z"
    },
    "id": "U0Q0vFm7B6cg"
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot the losses\n",
    "ax1.plot(train_losses, label='Train Loss')\n",
    "ax1.plot(test_losses, label='Test Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Loss vs. Epoch')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot the accuracies\n",
    "ax2.plot(train_accs, label='Train Accuracy')\n",
    "ax2.plot(test_accs, label='Test Accuracy')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Accuracy vs. Epoch')\n",
    "ax2.legend()\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"2-cifar10_full_repacement.pdf\")\n",
    "# Display the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "res_dict = {\n",
    "    \"train_losses\": train_losses,\n",
    "    \"test_losses\": test_losses,\n",
    "    \"train_accs\": train_accs,\n",
    "    \"test_accs\": test_accs\n",
    "}\n",
    "\n",
    "with open(\"2-cifar10_full_replacement.json\", \"w\") as f:\n",
    "    json.dump(res_dict, f)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
